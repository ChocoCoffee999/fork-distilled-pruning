{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51ecf34-d1ab-4285-beb2-0aaf3e5bdb60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T01:48:09.513648Z",
     "iopub.status.busy": "2023-05-30T01:48:09.512844Z",
     "iopub.status.idle": "2023-05-30T01:48:22.563073Z",
     "shell.execute_reply": "2023-05-30T01:48:22.562305Z",
     "shell.execute_reply.started": "2023-05-30T01:48:09.513617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.13.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (66.1.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting kornia\n",
      "  Downloading kornia-0.6.12-py2.py3-none-any.whl (653 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.4/653.4 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from kornia) (1.12.1+cu116)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from kornia) (23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (4.4.0)\n",
      "Installing collected packages: kornia\n",
      "Successfully installed kornia-0.6.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting optuna\n",
      "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.41)\n",
      "Collecting cmaes>=0.9.1\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.4.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.models import resnet50, resnet34, resnet18, wide_resnet50_2, ResNet50_Weights, alexnet\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from flax.training import checkpoints\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "!pip install wandb\n",
    "!pip install kornia\n",
    "!pip install optuna\n",
    "import optuna\n",
    "import kornia\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131a0bf1-a86b-4af0-9767-54de55893237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T01:48:23.055447Z",
     "iopub.status.busy": "2023-05-30T01:48:23.055079Z",
     "iopub.status.idle": "2023-05-30T01:48:23.089562Z",
     "shell.execute_reply": "2023-05-30T01:48:23.088783Z",
     "shell.execute_reply.started": "2023-05-30T01:48:23.055422Z"
    }
   },
   "outputs": [],
   "source": [
    "from networks import ConvNet, AlexNet\n",
    "from distill import ParamDiffAug\n",
    "from utils import evaluate_synset, get_network\n",
    "import argparse\n",
    "#labels_train = torch.load('/datasets/mtt-cifar10-50-ipc/cifar10_50ipc_labels.pt')\n",
    "#images_train = torch.load('/datasets/mtt-cifar10-50-ipc/cifar10_50ipc_images.pt')\n",
    "labels_train = torch.load('./data/cifar10_10ipc_labels.pt')\n",
    "images_train = torch.load('./data/cifar10_10ipc_images.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7dd09d-22f0-43c7-8a0d-7afddd0ab18e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T01:48:32.311069Z",
     "iopub.status.busy": "2023-05-30T01:48:32.310235Z",
     "iopub.status.idle": "2023-05-30T01:48:34.715047Z",
     "shell.execute_reply": "2023-05-30T01:48:34.714524Z",
     "shell.execute_reply.started": "2023-05-30T01:48:32.311043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                                    train = True,\n",
    "                                                    transform = transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616]),]),\n",
    "                                                    download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                                    train = False,\n",
    "                                                    transform = transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616]),]),\n",
    "                                                    download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.Resize((32,32)),  #resises the image so it can be perfect for our model.\n",
    "                                      transforms.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n",
    "                                      transforms.RandomRotation(10),     #Rotates the image to a specified angel\n",
    "                                      transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
    "                                      transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n",
    "                                      transforms.ToTensor(), # comvert the image to tensor so that it can work with torch\n",
    "                                      transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616]), #Normalize all the images\n",
    "                               ])\n",
    "\n",
    "\n",
    "augmented_train_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                                    train = True,\n",
    "                                                    transform = transform_train,\n",
    "                                                    download=True)\n",
    "\n",
    "augmented_train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0cd085f-5189-4ed5-9074-9ab264e0fe92",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-23T19:36:01.112947Z",
     "iopub.status.busy": "2023-05-23T19:36:01.112160Z",
     "iopub.status.idle": "2023-05-23T19:36:01.173626Z",
     "shell.execute_reply": "2023-05-23T19:36:01.172543Z",
     "shell.execute_reply.started": "2023-05-23T19:36:01.112912Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#Get pretrained model to determine what is easy/hard\u001b[39;00m\n\u001b[1;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m AlexNet(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m args \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mNamespace(lr_net\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.01\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_eval_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;124m'\u001b[39m,batch_train\u001b[38;5;241m=\u001b[39m\u001b[43mbatch_size\u001b[49m,dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar10\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,dsa_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_crop_cutout_flip_scale_rotate\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa_param \u001b[38;5;241m=\u001b[39m ParamDiffAug(), dc_aug_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zca_trans\u001b[38;5;241m=\u001b[39mkornia\u001b[38;5;241m.\u001b[39menhance\u001b[38;5;241m.\u001b[39mZCAWhitening(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, compute_inv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;66;03m#, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m pretrained_model, acc_train_list, acc_test \u001b[38;5;241m=\u001b[39m evaluate_synset(\u001b[38;5;241m7\u001b[39m, model,images_train,labels_train,test_loader,args)\n\u001b[1;32m     54\u001b[0m easy_train_dataset \u001b[38;5;241m=\u001b[39m EasyHardCIFAR10Dataset(root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained_model \u001b[38;5;241m=\u001b[39m pretrained_model, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124measy\u001b[39m\u001b[38;5;124m'\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "class RandomCIFAR10Dataset(Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None, num_samples=1000):\n",
    "        self.cifar = torchvision.datasets.CIFAR10(root, train=True, download=True, transform=transform, target_transform=target_transform)\n",
    "        self.num_samples = num_samples\n",
    "        self.indices = torch.randperm(len(self.cifar))[:self.num_samples]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.cifar[self.indices[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "class EasyHardCIFAR10Dataset(Dataset):\n",
    "    def __init__(self, root, pretrained_model, transform=None, target_transform=None, mode='easy', num_samples=1000):\n",
    "        assert mode in ['easy', 'hard'], \"Mode should be 'easy' or 'hard'\"\n",
    "        self.cifar = CIFAR10(root, train=True, download=True, transform=transform, target_transform=target_transform)\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.mode = mode\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        self.pretrained_model.eval()\n",
    "        with torch.no_grad():\n",
    "            data, targets = zip(*[(data, target) for data, target in self.cifar])\n",
    "            data = torch.stack(data)\n",
    "            targets = torch.tensor(targets)\n",
    "            outputs = self.pretrained_model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "            # Get confidence scores and sort them\n",
    "            confidence_scores, indices = torch.sort(probs.max(dim=1).values, descending=True)\n",
    "            sorted_preds = preds[indices]\n",
    "            sorted_targets = targets[indices]\n",
    "\n",
    "            if mode == 'easy':\n",
    "                mask = sorted_preds == sorted_targets\n",
    "            else:  # mode == 'hard'\n",
    "                mask = sorted_preds != sorted_targets\n",
    "\n",
    "            # Select num_samples many samples\n",
    "            self.indices = indices[mask][:self.num_samples].tolist()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.cifar[self.indices[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "#Get pretrained model to determine what is easy/hard\n",
    "model = AlexNet(3,10).to('cuda')\n",
    "args = argparse.Namespace(lr_net='.01', device='cuda', epoch_eval_train='1000',batch_train=batch_size,dataset='cifar10',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)) #, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "pretrained_model, acc_train_list, acc_test = evaluate_synset(7, model,images_train,labels_train,test_loader,args)\n",
    "\n",
    "easy_train_dataset = EasyHardCIFAR10Dataset(root = './data', pretrained_model = pretrained_model, transform=None, target_transform=None, mode='easy', num_samples=1000)\n",
    "\n",
    "easy_train_loader = torch.utils.data.DataLoader(dataset = easy_train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "hard_train_dataset = EasyHardCIFAR10Dataset(root = './data', pretrained_model = pretrained_model, transform=None, target_transform=None, mode='hard', num_samples=1000)\n",
    "\n",
    "hard_train_loader = torch.utils.data.DataLoader(dataset = hard_train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "random_train_dataset = RandomCIFAR10Dataset(root = './data', transform=None, target_transform=None, num_samples=1000)\n",
    "\n",
    "random_train_loader = torch.utils.data.DataLoader(dataset = random_train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893abb26-d2bb-406a-ab58-9d68cf9c6438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T02:12:54.054542Z",
     "iopub.status.busy": "2023-05-30T02:12:54.054270Z",
     "iopub.status.idle": "2023-05-30T02:12:54.078448Z",
     "shell.execute_reply": "2023-05-30T02:12:54.078006Z",
     "shell.execute_reply.started": "2023-05-30T02:12:54.054521Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model,train_loader, num_epochs, lr = .0008, weight_decay = .0008, gamma = .15, milestones = [50,65,80]):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    cost = nn.CrossEntropyLoss()\n",
    "    scheduler = MultiStepLR(optimizer, milestones=milestones, gamma= gamma)\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = cost(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "            \n",
    "def test(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(test_loader): \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            test_output = model(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            correct += (pred_y == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        accuracy = correct / total\n",
    "\n",
    "    print('Test Accuracy:', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def get_parameters_to_prune(model):\n",
    "    parameters_to_prune = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "    return tuple(parameters_to_prune)\n",
    "\n",
    "def sparsity_print(model):\n",
    "    prune.global_unstructured(get_parameters_to_prune(model),pruning_method=prune.L1Unstructured,amount=0)\n",
    "    zero = total = 0\n",
    "    for module, _ in get_parameters_to_prune(model):\n",
    "        zero += float(torch.sum(module.weight == 0))\n",
    "        total += float(module.weight.nelement())\n",
    "    print('Number of Zero Weights:', zero)\n",
    "    print('Total Number of Weights:', total)\n",
    "    print('Sparsity', zero/total)\n",
    "    #TODO: Implement Node Sparsity\n",
    "    return zero, total\n",
    "\n",
    "#Standard IMP with Weight Rewinding, name is a string that allows us to save models/logs appropriately, path is the location of folder we save to, start_iter should be 0 but if a experiment stops halfway through it allows us to begin there,\n",
    "#amount = % params pruned each pruning iteration, save_model downloads each model at every iter, reinit is boolean value if we want to test results on reinitialized weights\n",
    "#reinit_model is the specific model that holds the reinitialized weights\n",
    "def LotteryTicketRewinding(model, name, path, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 60, k = 1, amount = .2, save_model = True, seed = 0, reinit = False, reinit_model = None):\n",
    "    torch.manual_seed(seed)\n",
    "    zeros = []\n",
    "    totals = []\n",
    "    acc = []\n",
    "    reinit_acc = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    \n",
    "    #Create Rewind Weights after training K epochs\n",
    "    train(model, train_loader,num_epochs = k)\n",
    "    torch.save(model.state_dict(), path + name + '_RewindWeights' + '_' + str(k))\n",
    "    model_rewind = copy.deepcopy(model).to(device)\n",
    "    \n",
    "    #Finish off the pretraining\n",
    "    train(model, train_loader,num_epochs = num_epochs - k)\n",
    "\n",
    "    #Lottery Ticket Rewinding: Prune, Rewind, Train\n",
    "    for i in range(start_iter,end_iter):\n",
    "        print('LTR Iteration:', i+1)\n",
    "        #Prune\n",
    "        prune.global_unstructured(get_parameters_to_prune(model),pruning_method=prune.L1Unstructured,amount=amount)\n",
    "        #Rewind Weights\n",
    "        for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "            with torch.no_grad():\n",
    "                module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                module.weight_orig.copy_(module_rewind.weight)\n",
    "        #Train Weights\n",
    "        train(model, train_loader,num_epochs = num_epochs)\n",
    "        \n",
    "        #Log Results\n",
    "        zero, total = sparsity_print(model)\n",
    "        zeros.append(zero)\n",
    "        totals.append(total)\n",
    "        acc.append(test(model, test_loader))\n",
    "        if save_model:\n",
    "            torch.save(model.state_dict(), path + name + '_iter' + str(i+1))\n",
    "            \n",
    "        if reinit:\n",
    "            #Rewind Weights\n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_reinit = get_parameters_to_prune(reinit_model)[idx][0]\n",
    "                    module.weight_orig.copy_(module_reinit.weight)\n",
    "                    \n",
    "            train(model, train_loader,num_epochs = num_epochs)\n",
    "            reinit_acc.append(test(model, test_loader))\n",
    "            \n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                    module.weight_orig.copy_(module_rewind.weight)\n",
    "        else:\n",
    "            reinit_acc.append(0)\n",
    "            \n",
    "        np.save(path + name + '_log', np.array([acc,zeros,totals,reinit_acc]))\n",
    "    \n",
    "    pass\n",
    "  \n",
    "#Generate full sparsity curve with retraining for random pruning, this is not a method to compute a single, high-sparisty model with random pruning. This generates and trains models at all sparsities for comparison\n",
    "def RandomPruning(model, name, path, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 60, amount = .2, save_model = True, seed = 0):\n",
    "    torch.manual_seed(seed)\n",
    "    zeros = []\n",
    "    totals = []\n",
    "    acc = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    \n",
    "    model_rewind = copy.deepcopy(model).to(device)\n",
    "    \n",
    "    for i in range(start_iter,end_iter):\n",
    "        print('Random Pruning Iteration:', i+1)\n",
    "        #Prune\n",
    "        prune.global_unstructured(get_parameters_to_prune(model),pruning_method=prune.RandomUnstructured,amount=amount)\n",
    "        #Train Weights\n",
    "        train(model, train_loader,num_epochs = num_epochs)\n",
    "        \n",
    "        #Log Results\n",
    "        zero, total = sparsity_print(model)\n",
    "        zeros.append(zero)\n",
    "        totals.append(total)\n",
    "        acc.append(test(model, test_loader))\n",
    "\n",
    "            \n",
    "        #Rewind Weights to save them\n",
    "        for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "            with torch.no_grad():\n",
    "                module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                module.weight_orig.copy_(module_rewind.weight)\n",
    "                \n",
    "        if save_model:\n",
    "            torch.save(model.state_dict(), path + name + '_iter' + str(i+1))\n",
    "            \n",
    "        np.save(path + name + '_log', np.array([acc,zeros,totals]))\n",
    "    \n",
    "#Generate full sparsity curve to compare with LTR\n",
    "def DistilledPruning(model, name, path, images_train, labels_train, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs_distilled = 1000, num_epochs_real = 60, k = 0, amount = .2, save_model = True, validate = False, seed = 0, reinit = False, reinit_model = None, distilled_lr = .01):\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    accs = []\n",
    "    zeros = []\n",
    "    totals = []\n",
    "    reinit_acc = []\n",
    "    \n",
    "    model_rewind = copy.deepcopy(model).to(device)\n",
    "    torch.save(model.state_dict(), path + name + '_RewindWeights' + '_' + str(k))\n",
    "    \n",
    "    if k != 0:\n",
    "        args = argparse.Namespace(lr_net=str(distilled_lr), device='cuda', epoch_eval_train=str(k),batch_train=512,dataset='cifar10',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)) #, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "        model_rewind, acc_train_list, acc_test = evaluate_synset(0, model_rewind,images_train,labels_train,test_loader,args)\n",
    "        \n",
    "    \n",
    "    for i in range(start_iter,end_iter):\n",
    "        print('Distilled Pruning Iteration ', i)\n",
    "        args = argparse.Namespace(lr_net='.01', device='cuda', epoch_eval_train=str(num_epochs_distilled),batch_train=512,dataset='cifar10',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)) #, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "        #MTT Training on Distilled Data\n",
    "        model, acc_train_list, acc_test = evaluate_synset(i+1, model,images_train,labels_train,test_loader,args)\n",
    "        prune.global_unstructured(get_parameters_to_prune(model),pruning_method=prune.L1Unstructured,amount=amount)\n",
    "        #Rewind Weights\n",
    "        for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "            with torch.no_grad():\n",
    "                module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                module.weight_orig.copy_(module_rewind.weight)\n",
    "    \n",
    "        if save_model:\n",
    "            torch.save(model.state_dict(), path + name + '_iter' + str(i+1))\n",
    "            \n",
    "        if validate:\n",
    "            train(model, train_loader,num_epochs = num_epochs_real)\n",
    "            accs.append(test(model, test_loader))\n",
    "            zero, total = sparsity_print(model)\n",
    "            zeros.append(zero)\n",
    "            totals.append(total)\n",
    "            #Rewind Weights\n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                    module.weight_orig.copy_(module_rewind.weight)\n",
    "                    \n",
    "            np.save(path + name + '_log', np.array([accs, zeros, totals, reinit_acc]))\n",
    "        \n",
    "        if reinit:\n",
    "            #Rewind Weights to Reinit Model\n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_reinit = get_parameters_to_prune(reinit_model)[idx][0]\n",
    "                    module.weight_orig.copy_(module_reinit.weight)\n",
    "                    \n",
    "            train(model, train_loader,num_epochs = num_epochs_real)\n",
    "            reinit_acc.append(test(model, test_loader))\n",
    "            \n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                    module.weight_orig.copy_(module_rewind.weight)\n",
    "            np.save(path + name + '_log', np.array([accs, zeros, totals, reinit_acc]))\n",
    "        else:\n",
    "            reinit_acc.append(0)\n",
    "            \n",
    "    if not validate:\n",
    "        train(model, train_loader,num_epochs = num_epochs_real)\n",
    "        acc = (test(model, test_loader))\n",
    "        zero, total = sparsity_print(model)\n",
    "        np.save(path + name + '_log', np.array([acc, zero, total, reinit]))\n",
    "    \n",
    "path = './model_results_cifar10/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f51b0f-23af-4196-a0e7-61cf69325e3b",
   "metadata": {},
   "source": [
    "Distilled Training Params: .085 lr and 1300 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7620b4b2-a6b9-4e28-88e9-e4065487720b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T02:14:26.287090Z",
     "iopub.status.busy": "2023-05-30T02:14:26.286320Z",
     "iopub.status.idle": "2023-05-30T02:17:18.681743Z",
     "shell.execute_reply": "2023-05-30T02:17:18.680927Z",
     "shell.execute_reply.started": "2023-05-30T02:14:26.287068Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 58.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:14:34] Evaluate_01: epoch = 0500 train time = 8 s train loss = 2.299133 train acc = 0.0700, test acc = 0.1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 59.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:14:43] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.348136 train acc = 0.9000, test acc = 0.2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 57.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:14:51] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.011322 train acc = 1.0000, test acc = 0.3062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:09<00:00, 53.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:15:01] Evaluate_01: epoch = 0500 train time = 9 s train loss = 0.000739 train acc = 1.0000, test acc = 0.3154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 57.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:15:09] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.003284 train acc = 1.0000, test acc = 0.3203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 58.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:15:18] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.009369 train acc = 1.0000, test acc = 0.3154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 61.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:15:26] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000163 train acc = 1.0000, test acc = 0.3254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 58.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:15:35] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000531 train acc = 1.0000, test acc = 0.3338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 56.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:15:44] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.001921 train acc = 1.0000, test acc = 0.3241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:09<00:00, 54.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:15:53] Evaluate_01: epoch = 0500 train time = 9 s train loss = 0.000930 train acc = 1.0000, test acc = 0.3198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 61.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:16:01] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000200 train acc = 1.0000, test acc = 0.3237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 61.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:16:09] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000074 train acc = 1.0000, test acc = 0.3258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 61.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:16:18] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000148 train acc = 1.0000, test acc = 0.3228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 58.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:16:26] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000066 train acc = 1.0000, test acc = 0.3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 56.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:16:35] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000042 train acc = 1.0000, test acc = 0.3257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 59.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:16:43] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000103 train acc = 1.0000, test acc = 0.3212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 58.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:16:52] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000100 train acc = 1.0000, test acc = 0.3219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 60.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:17:00] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000427 train acc = 1.0000, test acc = 0.3248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:08<00:00, 56.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:17:09] Evaluate_01: epoch = 0500 train time = 8 s train loss = 0.000306 train acc = 1.0000, test acc = 0.3237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:09<00:00, 54.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:17:18] Evaluate_01: epoch = 0500 train time = 9 s train loss = 0.000072 train acc = 1.0000, test acc = 0.3262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(3,10).to('cuda')\n",
    "args = argparse.Namespace(lr_net=str(.007), device='cuda', epoch_eval_train=str(5\n",
    "                                                                                00),batch_train=100,dataset='cifar10',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True))                        \n",
    "for i in range(20):\n",
    "    model, acc_train_list, acc_test = evaluate_synset(1, model,images_train,labels_train,test_loader,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b423c72d-ea92-4904-a534-ecc4777513ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T01:58:50.790464Z",
     "iopub.status.busy": "2023-05-30T01:58:50.789793Z",
     "iopub.status.idle": "2023-05-30T02:12:16.028812Z",
     "shell.execute_reply": "2023-05-30T02:12:16.027640Z",
     "shell.execute_reply.started": "2023-05-30T01:58:50.790440Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 01:58:50,793]\u001b[0m A new study created in memory with name: no-name-37b6b398-9c9f-458e-b060-89c4733957d3\u001b[0m\n",
      "100%|██████████| 3001/3001 [00:42<00:00, 70.97it/s]\n",
      "\u001b[32m[I 2023-05-30 01:59:33,096]\u001b[0m Trial 0 finished with value: 0.3284 and parameters: {'learning_rate': 0.02310179288511339}. Best is trial 0 with value: 0.3284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 01:59:33] Evaluate_01: epoch = 3000 train time = 42 s train loss = 0.000437 train acc = 1.0000, test acc = 0.3284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 70.59it/s]\n",
      "\u001b[32m[I 2023-05-30 02:00:15,627]\u001b[0m Trial 1 finished with value: 0.3269 and parameters: {'learning_rate': 0.018072629718177063}. Best is trial 0 with value: 0.3284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:00:15] Evaluate_01: epoch = 3000 train time = 42 s train loss = 0.000784 train acc = 1.0000, test acc = 0.3269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 70.23it/s]\n",
      "\u001b[32m[I 2023-05-30 02:00:58,372]\u001b[0m Trial 2 finished with value: 0.1 and parameters: {'learning_rate': 0.0372786551854656}. Best is trial 0 with value: 0.3284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:00:58] Evaluate_01: epoch = 3000 train time = 42 s train loss = nan train acc = 0.1000, test acc = 0.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.41it/s]\n",
      "\u001b[32m[I 2023-05-30 02:01:41,621]\u001b[0m Trial 3 finished with value: 0.3135 and parameters: {'learning_rate': 0.01663794574883109}. Best is trial 0 with value: 0.3284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:01:41] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.006120 train acc = 1.0000, test acc = 0.3135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 70.19it/s]\n",
      "\u001b[32m[I 2023-05-30 02:02:24,398]\u001b[0m Trial 4 finished with value: 0.3232 and parameters: {'learning_rate': 0.02303391407430934}. Best is trial 0 with value: 0.3284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:02:24] Evaluate_01: epoch = 3000 train time = 42 s train loss = 0.000427 train acc = 1.0000, test acc = 0.3232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.71it/s]\n",
      "\u001b[32m[I 2023-05-30 02:03:08,092]\u001b[0m Trial 5 finished with value: 0.3202 and parameters: {'learning_rate': 0.03717307116327658}. Best is trial 0 with value: 0.3284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:03:08] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.000490 train acc = 1.0000, test acc = 0.3202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.21it/s]\n",
      "\u001b[32m[I 2023-05-30 02:03:51,466]\u001b[0m Trial 6 finished with value: 0.3298 and parameters: {'learning_rate': 0.015936678260982853}. Best is trial 6 with value: 0.3298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:03:51] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.000756 train acc = 1.0000, test acc = 0.3298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 70.31it/s]\n",
      "\u001b[32m[I 2023-05-30 02:04:34,166]\u001b[0m Trial 7 finished with value: 0.3341 and parameters: {'learning_rate': 0.0242413892433275}. Best is trial 7 with value: 0.3341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:04:34] Evaluate_01: epoch = 3000 train time = 42 s train loss = 0.000416 train acc = 1.0000, test acc = 0.3341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.12it/s]\n",
      "\u001b[32m[I 2023-05-30 02:05:18,892]\u001b[0m Trial 8 finished with value: 0.3384 and parameters: {'learning_rate': 0.013692409636334151}. Best is trial 8 with value: 0.3384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:05:18] Evaluate_01: epoch = 3000 train time = 44 s train loss = 0.002286 train acc = 1.0000, test acc = 0.3384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.38it/s]\n",
      "\u001b[32m[I 2023-05-30 02:06:02,162]\u001b[0m Trial 9 finished with value: 0.3227 and parameters: {'learning_rate': 0.012011444326265639}. Best is trial 8 with value: 0.3384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:06:02] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.001083 train acc = 1.0000, test acc = 0.3227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 70.16it/s]\n",
      "\u001b[32m[I 2023-05-30 02:06:44,955]\u001b[0m Trial 10 finished with value: 0.2881 and parameters: {'learning_rate': 0.0010649146182848332}. Best is trial 8 with value: 0.3384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:06:44] Evaluate_01: epoch = 3000 train time = 42 s train loss = 0.129216 train acc = 0.9600, test acc = 0.2881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.36it/s]\n",
      "\u001b[32m[I 2023-05-30 02:07:28,242]\u001b[0m Trial 11 finished with value: 0.2964 and parameters: {'learning_rate': 0.028058313249173655}. Best is trial 8 with value: 0.3384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:07:28] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.000148 train acc = 1.0000, test acc = 0.2964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.33it/s]\n",
      "\u001b[32m[I 2023-05-30 02:08:11,548]\u001b[0m Trial 12 finished with value: 0.3292 and parameters: {'learning_rate': 0.010604131525815111}. Best is trial 8 with value: 0.3384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:08:11] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.001578 train acc = 1.0000, test acc = 0.3292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.59it/s]\n",
      "\u001b[32m[I 2023-05-30 02:08:54,691]\u001b[0m Trial 13 finished with value: 0.3236 and parameters: {'learning_rate': 0.030983003579843}. Best is trial 8 with value: 0.3384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:08:54] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.000247 train acc = 1.0000, test acc = 0.3236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 70.35it/s]\n",
      "\u001b[32m[I 2023-05-30 02:09:37,367]\u001b[0m Trial 14 finished with value: 0.2997 and parameters: {'learning_rate': 0.027394023027264253}. Best is trial 8 with value: 0.3384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:09:37] Evaluate_01: epoch = 3000 train time = 42 s train loss = 0.000968 train acc = 1.0000, test acc = 0.2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 69.90it/s]\n",
      "\u001b[32m[I 2023-05-30 02:10:20,321]\u001b[0m Trial 15 finished with value: 0.3561 and parameters: {'learning_rate': 0.0073087471076532864}. Best is trial 15 with value: 0.3561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:10:20] Evaluate_01: epoch = 3000 train time = 42 s train loss = 0.001057 train acc = 1.0000, test acc = 0.3561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.70it/s]\n",
      "\u001b[32m[I 2023-05-30 02:11:03,401]\u001b[0m Trial 16 finished with value: 0.3374 and parameters: {'learning_rate': 0.005233835384086168}. Best is trial 15 with value: 0.3561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:11:03] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.001276 train acc = 1.0000, test acc = 0.3374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 71.43it/s]\n",
      "\u001b[32m[I 2023-05-30 02:11:45,433]\u001b[0m Trial 17 finished with value: 0.2966 and parameters: {'learning_rate': 0.009124869761263386}. Best is trial 15 with value: 0.3561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 02:11:45] Evaluate_01: epoch = 3000 train time = 42 s train loss = 0.005263 train acc = 1.0000, test acc = 0.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 2092/3001 [00:30<00:13, 68.65it/s]\n",
      "\u001b[33m[W 2023-05-30 02:12:15,922]\u001b[0m Trial 18 failed with parameters: {'learning_rate': 0.006584268801467397} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_32/4138845070.py\", line 9, in objective\n",
      "    model, acc_train_list, acc_test = evaluate_synset(1, model,images_train,labels_train,test_loader,args)\n",
      "  File \"/notebooks/mtt_distillation/utils.py\", line 371, in evaluate_synset\n",
      "    loss_train, acc_train = epoch('train', trainloader, net, optimizer, criterion, args, aug=True, texture=texture)\n",
      "  File \"/notebooks/mtt_distillation/utils.py\", line 334, in epoch\n",
      "    acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-05-30 02:12:15,925]\u001b[0m Trial 18 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acc_test\n\u001b[1;32m     13\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler())\n\u001b[0;32m---> 14\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [13], line 9\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m AlexNet(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m args \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mNamespace(lr_net\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_eval_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m3000\u001b[39m),batch_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar10\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,dsa_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_crop_cutout_flip_scale_rotate\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa_param \u001b[38;5;241m=\u001b[39m ParamDiffAug(), dc_aug_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zca_trans\u001b[38;5;241m=\u001b[39mkornia\u001b[38;5;241m.\u001b[39menhance\u001b[38;5;241m.\u001b[39mZCAWhitening(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, compute_inv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))                        \n\u001b[0;32m----> 9\u001b[0m model, acc_train_list, acc_test \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_synset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimages_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc_test\n",
      "File \u001b[0;32m/notebooks/mtt_distillation/utils.py:371\u001b[0m, in \u001b[0;36mevaluate_synset\u001b[0;34m(it_eval, net, images_train, labels_train, testloader, args, return_loss, texture)\u001b[0m\n\u001b[1;32m    368\u001b[0m loss_train_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(Epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 371\u001b[0m     loss_train, acc_train \u001b[38;5;241m=\u001b[39m \u001b[43mepoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     acc_train_list\u001b[38;5;241m.\u001b[39mappend(acc_train)\n\u001b[1;32m    373\u001b[0m     loss_train_list\u001b[38;5;241m.\u001b[39mappend(loss_train)\n",
      "File \u001b[0;32m/notebooks/mtt_distillation/utils.py:334\u001b[0m, in \u001b[0;36mepoch\u001b[0;34m(mode, dataloader, net, optimizer, criterion, args, aug, texture)\u001b[0m\n\u001b[1;32m    331\u001b[0m output \u001b[38;5;241m=\u001b[39m net(img)\n\u001b[1;32m    332\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, lab)\n\u001b[0;32m--> 334\u001b[0m acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mequal(np\u001b[38;5;241m.\u001b[39margmax(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), lab\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m    336\u001b[0m loss_avg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m*\u001b[39mn_b\n\u001b[1;32m    337\u001b[0m acc_avg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_float('learning_rate', 8e-4, 4e-2),\n",
    "              }\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    model = AlexNet(3,10).to('cuda')\n",
    "    args = argparse.Namespace(lr_net=str(params['learning_rate']), device='cuda', epoch_eval_train=str(3000),batch_train=100,dataset='cifar10',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True))                        \n",
    "    model, acc_train_list, acc_test = evaluate_synset(1, model,images_train,labels_train,test_loader,args)\n",
    "\n",
    "    return acc_test\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e7c885a-47f1-49b3-8cff-97b6a057898e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T15:54:00.912636Z",
     "iopub.status.busy": "2023-05-26T15:54:00.911962Z",
     "iopub.status.idle": "2023-05-26T16:00:45.113627Z",
     "shell.execute_reply": "2023-05-26T16:00:45.112740Z",
     "shell.execute_reply.started": "2023-05-26T15:54:00.912608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1301/1301 [06:44<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-26 16:00:45] Evaluate_01: epoch = 1300 train time = 404 s train loss = nan train acc = 0.0100, test acc = 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(3,100).to('cuda')\n",
    "args = argparse.Namespace(lr_net='.01', device='cuda', epoch_eval_train=str(1300),batch_train=512,dataset='cifar100',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)) #, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "model, acc_train_list, acc_test = evaluate_synset(1, model,images_train,labels_train,test_loader,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9478a-58a5-4e26-9289-90a36529db4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T06:58:58.532373Z",
     "iopub.status.busy": "2023-05-30T06:58:58.531589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled Pruning Iteration  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 06:59:41] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.000305 train acc = 1.0000, test acc = 0.3054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/96052406.py:197: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.save(path + name + '_log', np.array([accs, zeros, totals, reinit_acc]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.817\n",
      "Number of Zero Weights: 374268.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.20001154319720912\n",
      "Distilled Pruning Iteration  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:46<00:00, 65.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 07:07:50] Evaluate_02: epoch = 3000 train time = 46 s train loss = 0.001122 train acc = 1.0000, test acc = 0.3094\n",
      "Test Accuracy: 0.8112\n",
      "Number of Zero Weights: 673664.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.36001094466105754\n",
      "Distilled Pruning Iteration  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 07:15:55] Evaluate_03: epoch = 3000 train time = 43 s train loss = 0.000083 train acc = 1.0000, test acc = 0.3186\n",
      "Test Accuracy: 0.8066\n",
      "Number of Zero Weights: 913170.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.4880046942335317\n",
      "Distilled Pruning Iteration  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 70.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 07:23:59] Evaluate_04: epoch = 3000 train time = 42 s train loss = 0.001013 train acc = 1.0000, test acc = 0.3206\n",
      "Test Accuracy: 0.7978\n",
      "Number of Zero Weights: 1104782.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.5904035416239141\n",
      "Distilled Pruning Iteration  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 07:32:01] Evaluate_05: epoch = 3000 train time = 43 s train loss = 0.000208 train acc = 1.0000, test acc = 0.3410\n",
      "Test Accuracy: 0.7887\n",
      "Number of Zero Weights: 1258067.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.6723201612627403\n",
      "Distilled Pruning Iteration  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 68.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 07:40:05] Evaluate_06: epoch = 3000 train time = 44 s train loss = 0.000841 train acc = 1.0000, test acc = 0.3285\n",
      "Test Accuracy: 0.7851\n",
      "Number of Zero Weights: 1380702.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.7378571978247486\n",
      "Distilled Pruning Iteration  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 07:48:12] Evaluate_07: epoch = 3000 train time = 43 s train loss = 0.008698 train acc = 1.0000, test acc = 0.3251\n",
      "Test Accuracy: 0.789\n",
      "Number of Zero Weights: 1478810.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.7902868270743553\n",
      "Distilled Pruning Iteration  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 07:56:14] Evaluate_08: epoch = 3000 train time = 43 s train loss = 0.000292 train acc = 1.0000, test acc = 0.3291\n",
      "Test Accuracy: 0.797\n",
      "Number of Zero Weights: 1557293.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.8322287134892947\n",
      "Distilled Pruning Iteration  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:46<00:00, 63.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 08:04:24] Evaluate_09: epoch = 3000 train time = 46 s train loss = 0.000593 train acc = 1.0000, test acc = 0.3234\n",
      "Test Accuracy: 0.7902\n",
      "Number of Zero Weights: 1620079.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.865782008858335\n",
      "Distilled Pruning Iteration  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 08:12:30] Evaluate_10: epoch = 3000 train time = 44 s train loss = 0.003934 train acc = 1.0000, test acc = 0.3209\n",
      "Test Accuracy: 0.7895\n",
      "Number of Zero Weights: 1670312.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.8926268896641357\n",
      "Distilled Pruning Iteration  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 66.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 08:20:38] Evaluate_11: epoch = 3000 train time = 45 s train loss = 0.001388 train acc = 1.0000, test acc = 0.3165\n",
      "Test Accuracy: 0.7853\n",
      "Number of Zero Weights: 1710495.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9141009773240304\n",
      "Distilled Pruning Iteration  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 66.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 08:28:44] Evaluate_12: epoch = 3000 train time = 45 s train loss = 0.003203 train acc = 1.0000, test acc = 0.3157\n",
      "Test Accuracy: 0.7866\n",
      "Number of Zero Weights: 1742643.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9312811025035912\n",
      "Distilled Pruning Iteration  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 08:36:47] Evaluate_13: epoch = 3000 train time = 43 s train loss = 0.001191 train acc = 1.0000, test acc = 0.3107\n",
      "Test Accuracy: 0.7774\n",
      "Number of Zero Weights: 1768360.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9450244544770504\n",
      "Distilled Pruning Iteration  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 65.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 08:44:51] Evaluate_14: epoch = 3000 train time = 45 s train loss = 0.000891 train acc = 1.0000, test acc = 0.2978\n",
      "Test Accuracy: 0.7783\n",
      "Number of Zero Weights: 1788934.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.956019349818729\n",
      "Distilled Pruning Iteration  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 08:52:53] Evaluate_15: epoch = 3000 train time = 43 s train loss = 0.001443 train acc = 1.0000, test acc = 0.2984\n",
      "Test Accuracy: 0.7684\n",
      "Number of Zero Weights: 1805394.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9648156936178945\n",
      "Distilled Pruning Iteration  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 09:01:07] Evaluate_16: epoch = 3000 train time = 44 s train loss = 0.004140 train acc = 1.0000, test acc = 0.3012\n",
      "Test Accuracy: 0.7592\n",
      "Number of Zero Weights: 1818562.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9718527686572269\n",
      "Distilled Pruning Iteration  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 09:09:16] Evaluate_17: epoch = 3000 train time = 44 s train loss = 0.003102 train acc = 1.0000, test acc = 0.3131\n",
      "Test Accuracy: 0.7564\n",
      "Number of Zero Weights: 1829096.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9774822149257815\n",
      "Distilled Pruning Iteration  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:46<00:00, 65.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 09:17:27] Evaluate_18: epoch = 3000 train time = 46 s train loss = 0.000700 train acc = 1.0000, test acc = 0.3270\n",
      "Test Accuracy: 0.7486\n",
      "Number of Zero Weights: 1837523.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9819856650591696\n",
      "Distilled Pruning Iteration  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 65.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 09:25:38] Evaluate_19: epoch = 3000 train time = 45 s train loss = 0.001380 train acc = 1.0000, test acc = 0.3060\n",
      "Test Accuracy: 0.7383\n",
      "Number of Zero Weights: 1844265.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9855886389287913\n",
      "Distilled Pruning Iteration  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 70.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 09:33:49] Evaluate_20: epoch = 3000 train time = 42 s train loss = 0.001949 train acc = 1.0000, test acc = 0.3061\n",
      "Test Accuracy: 0.7288\n",
      "Number of Zero Weights: 1849658.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9884706973801217\n",
      "Distilled Pruning Iteration  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 09:41:56] Evaluate_21: epoch = 3000 train time = 43 s train loss = 0.000609 train acc = 1.0000, test acc = 0.3032\n",
      "Test Accuracy: 0.7173\n",
      "Number of Zero Weights: 1853973.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.990776664785553\n",
      "Distilled Pruning Iteration  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:41<00:00, 71.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 09:50:02] Evaluate_22: epoch = 3000 train time = 41 s train loss = 0.000137 train acc = 1.0000, test acc = 0.3241\n",
      "Test Accuracy: 0.6969\n",
      "Number of Zero Weights: 1857425.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.992621438709898\n",
      "Distilled Pruning Iteration  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 66.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 09:58:12] Evaluate_23: epoch = 3000 train time = 45 s train loss = 0.003394 train acc = 1.0000, test acc = 0.2935\n",
      "Test Accuracy: 0.6869\n",
      "Number of Zero Weights: 1860186.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9940969372050071\n",
      "Distilled Pruning Iteration  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 10:06:22] Evaluate_24: epoch = 3000 train time = 43 s train loss = 0.002141 train acc = 1.0000, test acc = 0.2846\n",
      "Test Accuracy: 0.6599\n",
      "Number of Zero Weights: 1862395.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9952774428825502\n",
      "Distilled Pruning Iteration  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 10:14:33] Evaluate_25: epoch = 3000 train time = 44 s train loss = 0.014270 train acc = 1.0000, test acc = 0.2745\n",
      "Test Accuracy: 0.6255\n",
      "Number of Zero Weights: 1864162.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9962217405431288\n",
      "Distilled Pruning Iteration  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 10:22:43] Evaluate_26: epoch = 3000 train time = 44 s train loss = 2.302555 train acc = 0.1000, test acc = 0.0973\n",
      "Test Accuracy: 0.5613\n",
      "Number of Zero Weights: 1865576.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.996977392434503\n",
      "Distilled Pruning Iteration  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 68.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 10:30:53] Evaluate_27: epoch = 3000 train time = 44 s train loss = 2.302583 train acc = 0.1000, test acc = 0.1000\n",
      "Test Accuracy: 0.1\n",
      "Number of Zero Weights: 1866708.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.997582341473425\n",
      "Distilled Pruning Iteration  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 10:38:58] Evaluate_28: epoch = 3000 train time = 43 s train loss = 2.302585 train acc = 0.1000, test acc = 0.1000\n",
      "Test Accuracy: 0.1\n",
      "Number of Zero Weights: 1867613.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9980659800601956\n",
      "Distilled Pruning Iteration  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 10:47:05] Evaluate_29: epoch = 3000 train time = 43 s train loss = 2.302586 train acc = 0.1000, test acc = 0.1000\n",
      "Test Accuracy: 0.1\n",
      "Number of Zero Weights: 1868337.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9984528909296122\n",
      "Distilled Pruning Iteration  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 66.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 10:55:14] Evaluate_30: epoch = 3000 train time = 45 s train loss = 2.302586 train acc = 0.1000, test acc = 0.1000\n",
      "Test Accuracy: 0.1\n",
      "Number of Zero Weights: 1868916.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9987623127436898\n",
      "Distilled Pruning Iteration  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 11:03:23] Evaluate_01: epoch = 3000 train time = 43 s train loss = 0.000584 train acc = 1.0000, test acc = 0.3142\n",
      "Test Accuracy: 0.8115\n",
      "Number of Zero Weights: 374257.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.20000566471714892\n",
      "Distilled Pruning Iteration  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 11:11:31] Evaluate_02: epoch = 3000 train time = 44 s train loss = 0.001188 train acc = 1.0000, test acc = 0.3299\n",
      "Test Accuracy: 0.8121\n",
      "Number of Zero Weights: 673665.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.36001147906833575\n",
      "Distilled Pruning Iteration  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 11:19:42] Evaluate_03: epoch = 3000 train time = 43 s train loss = 0.000167 train acc = 1.0000, test acc = 0.2990\n",
      "Test Accuracy: 0.7951\n",
      "Number of Zero Weights: 913173.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.4880062974553663\n",
      "Distilled Pruning Iteration  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 11:27:48] Evaluate_04: epoch = 3000 train time = 44 s train loss = 0.003788 train acc = 1.0000, test acc = 0.2763\n",
      "Test Accuracy: 0.7865\n",
      "Number of Zero Weights: 1104788.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.5904067480675833\n",
      "Distilled Pruning Iteration  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 11:35:57] Evaluate_05: epoch = 3000 train time = 43 s train loss = 0.000567 train acc = 1.0000, test acc = 0.2783\n",
      "Test Accuracy: 0.7868\n",
      "Number of Zero Weights: 1258075.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.6723244365209659\n",
      "Distilled Pruning Iteration  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 66.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 11:44:05] Evaluate_06: epoch = 3000 train time = 45 s train loss = 0.005503 train acc = 1.0000, test acc = 0.2730\n",
      "Test Accuracy: 0.7864\n",
      "Number of Zero Weights: 1380706.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.7378593354538614\n",
      "Distilled Pruning Iteration  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 66.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 11:52:17] Evaluate_07: epoch = 3000 train time = 44 s train loss = 0.009632 train acc = 1.0000, test acc = 0.2822\n",
      "Test Accuracy: 0.7836\n",
      "Number of Zero Weights: 1478808.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.7902857582597989\n",
      "Distilled Pruning Iteration  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 12:00:24] Evaluate_08: epoch = 3000 train time = 44 s train loss = 0.004364 train acc = 1.0000, test acc = 0.2868\n",
      "Test Accuracy: 0.7873\n",
      "Number of Zero Weights: 1557293.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.8322287134892947\n",
      "Distilled Pruning Iteration  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 68.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 12:08:28] Evaluate_09: epoch = 3000 train time = 44 s train loss = 0.000884 train acc = 1.0000, test acc = 0.2826\n",
      "Test Accuracy: 0.7911\n",
      "Number of Zero Weights: 1620081.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.8657830776728914\n",
      "Distilled Pruning Iteration  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 66.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 12:16:36] Evaluate_10: epoch = 3000 train time = 44 s train loss = 0.007581 train acc = 1.0000, test acc = 0.2772\n",
      "Test Accuracy: 0.7841\n",
      "Number of Zero Weights: 1670310.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.8926258208495793\n",
      "Distilled Pruning Iteration  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 66.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 12:24:46] Evaluate_11: epoch = 3000 train time = 45 s train loss = 0.000967 train acc = 1.0000, test acc = 0.2769\n",
      "Test Accuracy: 0.785\n",
      "Number of Zero Weights: 1710495.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9141009773240304\n",
      "Distilled Pruning Iteration  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 12:32:58] Evaluate_12: epoch = 3000 train time = 43 s train loss = 0.002231 train acc = 1.0000, test acc = 0.2724\n",
      "Test Accuracy: 0.7802\n",
      "Number of Zero Weights: 1742642.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.931280568096313\n",
      "Distilled Pruning Iteration  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 12:41:07] Evaluate_13: epoch = 3000 train time = 43 s train loss = 0.007558 train acc = 1.0000, test acc = 0.2829\n",
      "Test Accuracy: 0.7785\n",
      "Number of Zero Weights: 1768360.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9450244544770504\n",
      "Distilled Pruning Iteration  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 12:49:14] Evaluate_14: epoch = 3000 train time = 44 s train loss = 0.001074 train acc = 1.0000, test acc = 0.2714\n",
      "Test Accuracy: 0.7714\n",
      "Number of Zero Weights: 1788934.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.956019349818729\n",
      "Distilled Pruning Iteration  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:46<00:00, 63.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 12:57:22] Evaluate_15: epoch = 3000 train time = 46 s train loss = 0.001345 train acc = 1.0000, test acc = 0.2753\n",
      "Test Accuracy: 0.7682\n",
      "Number of Zero Weights: 1805394.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9648156936178945\n",
      "Distilled Pruning Iteration  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 13:05:32] Evaluate_16: epoch = 3000 train time = 44 s train loss = 0.008015 train acc = 1.0000, test acc = 0.2732\n",
      "Test Accuracy: 0.7616\n",
      "Number of Zero Weights: 1818562.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9718527686572269\n",
      "Distilled Pruning Iteration  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 13:13:39] Evaluate_17: epoch = 3000 train time = 44 s train loss = 0.012542 train acc = 0.9900, test acc = 0.2847\n",
      "Test Accuracy: 0.7563\n",
      "Number of Zero Weights: 1829096.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9774822149257815\n",
      "Distilled Pruning Iteration  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 13:21:48] Evaluate_18: epoch = 3000 train time = 44 s train loss = 0.001331 train acc = 1.0000, test acc = 0.2780\n",
      "Test Accuracy: 0.7459\n",
      "Number of Zero Weights: 1837523.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9819856650591696\n",
      "Distilled Pruning Iteration  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:46<00:00, 64.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 13:29:58] Evaluate_19: epoch = 3000 train time = 46 s train loss = 0.005618 train acc = 1.0000, test acc = 0.2921\n",
      "Test Accuracy: 0.7373\n",
      "Number of Zero Weights: 1844265.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9855886389287913\n",
      "Distilled Pruning Iteration  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 13:38:07] Evaluate_20: epoch = 3000 train time = 43 s train loss = 0.004034 train acc = 1.0000, test acc = 0.2759\n",
      "Test Accuracy: 0.7251\n",
      "Number of Zero Weights: 1849658.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9884706973801217\n",
      "Distilled Pruning Iteration  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:42<00:00, 71.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 13:46:11] Evaluate_21: epoch = 3000 train time = 42 s train loss = 0.001314 train acc = 1.0000, test acc = 0.2706\n",
      "Test Accuracy: 0.7039\n",
      "Number of Zero Weights: 1853973.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.990776664785553\n",
      "Distilled Pruning Iteration  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 65.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 13:54:17] Evaluate_22: epoch = 3000 train time = 45 s train loss = 0.000393 train acc = 1.0000, test acc = 0.2844\n",
      "Test Accuracy: 0.6981\n",
      "Number of Zero Weights: 1857425.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.992621438709898\n",
      "Distilled Pruning Iteration  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 14:02:27] Evaluate_23: epoch = 3000 train time = 43 s train loss = 0.009974 train acc = 1.0000, test acc = 0.2805\n",
      "Test Accuracy: 0.6837\n",
      "Number of Zero Weights: 1860186.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9940969372050071\n",
      "Distilled Pruning Iteration  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 14:10:36] Evaluate_24: epoch = 3000 train time = 43 s train loss = 0.004610 train acc = 1.0000, test acc = 0.2855\n",
      "Test Accuracy: 0.6628\n",
      "Number of Zero Weights: 1862395.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9952774428825502\n",
      "Distilled Pruning Iteration  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 14:18:48] Evaluate_25: epoch = 3000 train time = 44 s train loss = 0.092388 train acc = 0.9700, test acc = 0.2975\n",
      "Test Accuracy: 0.6185\n",
      "Number of Zero Weights: 1864162.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9962217405431288\n",
      "Distilled Pruning Iteration  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 14:26:55] Evaluate_26: epoch = 3000 train time = 43 s train loss = 2.301520 train acc = 0.0900, test acc = 0.1472\n",
      "Test Accuracy: 0.55\n",
      "Number of Zero Weights: 1865576.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.996977392434503\n",
      "Distilled Pruning Iteration  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 65.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 14:35:09] Evaluate_27: epoch = 3000 train time = 45 s train loss = 2.302588 train acc = 0.1000, test acc = 0.1024\n",
      "Test Accuracy: 0.1\n",
      "Number of Zero Weights: 1866707.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9975818070661467\n",
      "Distilled Pruning Iteration  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 69.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 14:43:18] Evaluate_28: epoch = 3000 train time = 43 s train loss = 2.302585 train acc = 0.1000, test acc = 0.1000\n",
      "Test Accuracy: 0.1\n",
      "Number of Zero Weights: 1867612.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9980654456529174\n",
      "Distilled Pruning Iteration  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 14:51:25] Evaluate_29: epoch = 3000 train time = 44 s train loss = 2.302586 train acc = 0.1000, test acc = 0.1000\n",
      "Test Accuracy: 0.1\n",
      "Number of Zero Weights: 1868336.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.998452356522334\n",
      "Distilled Pruning Iteration  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 14:59:31] Evaluate_30: epoch = 3000 train time = 43 s train loss = 2.302586 train acc = 0.1000, test acc = 0.1000\n",
      "Test Accuracy: 0.1\n",
      "Number of Zero Weights: 1868915.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.9987617783364116\n",
      "Distilled Pruning Iteration  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 67.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 15:07:34] Evaluate_01: epoch = 3000 train time = 44 s train loss = 0.000250 train acc = 1.0000, test acc = 0.3244\n",
      "Test Accuracy: 0.8149\n",
      "Number of Zero Weights: 374266.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.2000104743826527\n",
      "Distilled Pruning Iteration  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:43<00:00, 68.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 15:15:36] Evaluate_02: epoch = 3000 train time = 43 s train loss = 0.000676 train acc = 1.0000, test acc = 0.3352\n",
      "Test Accuracy: 0.8145\n",
      "Number of Zero Weights: 673658.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.36000773821738835\n",
      "Distilled Pruning Iteration  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:46<00:00, 65.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 15:23:39] Evaluate_03: epoch = 3000 train time = 46 s train loss = 0.000109 train acc = 1.0000, test acc = 0.3403\n",
      "Test Accuracy: 0.8031\n",
      "Number of Zero Weights: 913166.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.4880025566044189\n",
      "Distilled Pruning Iteration  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 65.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 15:31:40] Evaluate_04: epoch = 3000 train time = 45 s train loss = 0.000955 train acc = 1.0000, test acc = 0.3369\n",
      "Test Accuracy: 0.7876\n",
      "Number of Zero Weights: 1104776.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.5904003351802449\n",
      "Distilled Pruning Iteration  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 66.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 15:39:44] Evaluate_05: epoch = 3000 train time = 45 s train loss = 0.000359 train acc = 1.0000, test acc = 0.3450\n",
      "Test Accuracy: 0.7848\n",
      "Number of Zero Weights: 1258070.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.6723217644845748\n",
      "Distilled Pruning Iteration  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:44<00:00, 66.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 15:47:45] Evaluate_06: epoch = 3000 train time = 44 s train loss = 0.000554 train acc = 1.0000, test acc = 0.3558\n",
      "Test Accuracy: 0.7788\n",
      "Number of Zero Weights: 1380701.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.7378566634174704\n",
      "Distilled Pruning Iteration  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:46<00:00, 64.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 15:55:49] Evaluate_07: epoch = 3000 train time = 46 s train loss = 0.001173 train acc = 1.0000, test acc = 0.3410\n",
      "Test Accuracy: 0.7877\n",
      "Number of Zero Weights: 1478806.0\n",
      "Total Number of Weights: 1871232.0\n",
      "Sparsity 0.7902846894452424\n",
      "Distilled Pruning Iteration  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:45<00:00, 66.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:03:51] Evaluate_08: epoch = 3000 train time = 45 s train loss = 0.000743 train acc = 1.0000, test acc = 0.3323\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    torch.manual_seed(i)\n",
    "    model = AlexNet(3,10)\n",
    "    DistilledPruning(model, 'dist_c10_ipc10_an_seed' + str(i), path, images_train, labels_train, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs_distilled = 3000, num_epochs_real = 60, k = 0, amount = .2, save_model = False, validate = True, seed = 0, reinit = False, reinit_model = None, distilled_lr = .007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1763be-3343-44f1-b2ad-3897c4c1adfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T02:40:42.664587Z",
     "iopub.status.busy": "2023-05-26T02:40:42.664303Z",
     "iopub.status.idle": "2023-05-26T06:26:45.241275Z",
     "shell.execute_reply": "2023-05-26T06:26:45.240325Z",
     "shell.execute_reply.started": "2023-05-26T02:40:42.664566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTR Iteration: 1\n",
      "Number of Zero Weights: 63770.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.20000125451625853\n",
      "Test Accuracy: 0.8143\n",
      "LTR Iteration: 2\n",
      "Number of Zero Weights: 114786.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.36000225812926534\n",
      "Test Accuracy: 0.8132\n",
      "LTR Iteration: 3\n",
      "Number of Zero Weights: 155598.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.48800055198715375\n",
      "Test Accuracy: 0.8118\n",
      "LTR Iteration: 4\n",
      "Number of Zero Weights: 188248.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.590400441589723\n",
      "Test Accuracy: 0.8094\n",
      "LTR Iteration: 5\n",
      "Number of Zero Weights: 214368.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.6723203532717784\n",
      "Test Accuracy: 0.8101\n",
      "LTR Iteration: 6\n",
      "Number of Zero Weights: 235264.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.7378562826174228\n",
      "Test Accuracy: 0.806\n",
      "LTR Iteration: 7\n",
      "Number of Zero Weights: 251981.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.7902856533520675\n",
      "Test Accuracy: 0.8042\n",
      "LTR Iteration: 8\n",
      "Number of Zero Weights: 265354.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.8322272681653954\n",
      "Test Accuracy: 0.8029\n",
      "LTR Iteration: 9\n",
      "Number of Zero Weights: 276053.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.8657824417904456\n",
      "Test Accuracy: 0.7962\n",
      "LTR Iteration: 10\n",
      "Number of Zero Weights: 284612.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.8926259534323565\n",
      "Test Accuracy: 0.7945\n",
      "LTR Iteration: 11\n",
      "Number of Zero Weights: 291459.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9141001354877559\n",
      "Test Accuracy: 0.7851\n",
      "LTR Iteration: 12\n",
      "Number of Zero Weights: 296937.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.931280735648334\n",
      "Test Accuracy: 0.7749\n",
      "LTR Iteration: 13\n",
      "Number of Zero Weights: 301319.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9450239612605379\n",
      "Test Accuracy: 0.7725\n",
      "LTR Iteration: 14\n",
      "Number of Zero Weights: 304825.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9560197962665596\n",
      "Test Accuracy: 0.7663\n",
      "LTR Iteration: 15\n",
      "Number of Zero Weights: 307630.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9648170915295062\n",
      "Test Accuracy: 0.7679\n",
      "LTR Iteration: 16\n",
      "Number of Zero Weights: 309874.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9718549277398635\n",
      "Test Accuracy: 0.757\n",
      "LTR Iteration: 17\n",
      "Number of Zero Weights: 311669.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.97748456945002\n",
      "Test Accuracy: 0.751\n",
      "LTR Iteration: 18\n",
      "Number of Zero Weights: 313105.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9819882828181453\n",
      "Test Accuracy: 0.7341\n",
      "LTR Iteration: 19\n",
      "Number of Zero Weights: 314254.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9855918807707748\n",
      "Test Accuracy: 0.7274\n",
      "LTR Iteration: 20\n",
      "Number of Zero Weights: 315173.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9884741318747491\n",
      "Test Accuracy: 0.7071\n",
      "LTR Iteration: 21\n",
      "Number of Zero Weights: 315908.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9907793054997993\n",
      "Test Accuracy: 0.6792\n",
      "LTR Iteration: 22\n",
      "Number of Zero Weights: 316496.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9926234443998394\n",
      "Test Accuracy: 0.6619\n",
      "LTR Iteration: 23\n",
      "Number of Zero Weights: 316966.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.994097501003613\n",
      "Test Accuracy: 0.6368\n",
      "LTR Iteration: 24\n",
      "Number of Zero Weights: 317342.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9952767462866319\n",
      "Test Accuracy: 0.628\n",
      "LTR Iteration: 25\n",
      "Number of Zero Weights: 317643.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9962207697711762\n",
      "Test Accuracy: 0.5611\n",
      "LTR Iteration: 26\n",
      "Number of Zero Weights: 317884.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.996976615816941\n",
      "Test Accuracy: 0.5451\n",
      "LTR Iteration: 27\n",
      "Number of Zero Weights: 318077.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9975819199116821\n",
      "Test Accuracy: 0.5434\n",
      "LTR Iteration: 28\n",
      "Number of Zero Weights: 318231.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9980649086712163\n",
      "Test Accuracy: 0.4777\n",
      "LTR Iteration: 29\n",
      "Number of Zero Weights: 318354.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9984506724207146\n",
      "Test Accuracy: 0.461\n",
      "LTR Iteration: 30\n",
      "Number of Zero Weights: 318453.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9987611651947009\n",
      "Test Accuracy: 0.4082\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    torch.manual_seed(i)\n",
    "    model = get_network('ConvNetW128', 3,10)\n",
    "    LotteryTicketRewinding(model, 'ltr_c10_seed' + str(i), path, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 60, k = 1, amount = .2, save_model = False, seed = i, reinit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a75ef5b-b092-4069-ad01-997f9305da6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T22:14:54.956970Z",
     "iopub.status.busy": "2023-05-25T22:14:54.956771Z",
     "iopub.status.idle": "2023-05-26T01:53:25.340736Z",
     "shell.execute_reply": "2023-05-26T01:53:25.340058Z",
     "shell.execute_reply.started": "2023-05-25T22:14:54.956949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Pruning Iteration: 1\n",
      "Number of Zero Weights: 100634.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.2000007949631137\n",
      "Test Accuracy: 0.8126\n",
      "Random Pruning Iteration: 2\n",
      "Number of Zero Weights: 181141.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.3600010334520478\n",
      "Test Accuracy: 0.7985\n",
      "Random Pruning Iteration: 3\n",
      "Number of Zero Weights: 245547.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.4880020192063088\n",
      "Test Accuracy: 0.7913\n",
      "Random Pruning Iteration: 4\n",
      "Number of Zero Weights: 297070.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.590399230475706\n",
      "Test Accuracy: 0.781\n",
      "Random Pruning Iteration: 5\n",
      "Number of Zero Weights: 338290.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.6723201793436785\n",
      "Test Accuracy: 0.7751\n",
      "Random Pruning Iteration: 6\n",
      "Number of Zero Weights: 371266.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.7378569384380564\n",
      "Test Accuracy: 0.7669\n",
      "Random Pruning Iteration: 7\n",
      "Number of Zero Weights: 397646.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.7902847557873315\n",
      "Test Accuracy: 0.7684\n",
      "Random Pruning Iteration: 8\n",
      "Number of Zero Weights: 418750.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.8322270096667514\n",
      "Test Accuracy: 0.7458\n",
      "Random Pruning Iteration: 9\n",
      "Number of Zero Weights: 435634.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.8657824026965149\n",
      "Test Accuracy: 0.7493\n",
      "Random Pruning Iteration: 10\n",
      "Number of Zero Weights: 449141.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.8926263196387687\n",
      "Test Accuracy: 0.7298\n",
      "Random Pruning Iteration: 11\n",
      "Number of Zero Weights: 459946.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9141002607479013\n",
      "Test Accuracy: 0.727\n",
      "Random Pruning Iteration: 12\n",
      "Number of Zero Weights: 468590.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9312794136352073\n",
      "Test Accuracy: 0.7261\n",
      "Random Pruning Iteration: 13\n",
      "Number of Zero Weights: 475506.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9450243258712796\n",
      "Test Accuracy: 0.7153\n",
      "Random Pruning Iteration: 14\n",
      "Number of Zero Weights: 481038.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9560186657339099\n",
      "Test Accuracy: 0.6958\n",
      "Random Pruning Iteration: 15\n",
      "Number of Zero Weights: 485464.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9648149325871279\n",
      "Test Accuracy: 0.6827\n",
      "Random Pruning Iteration: 16\n",
      "Number of Zero Weights: 489005.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9718523435512593\n",
      "Test Accuracy: 0.6704\n",
      "Random Pruning Iteration: 17\n",
      "Number of Zero Weights: 491838.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9774826698041211\n",
      "Test Accuracy: 0.6413\n",
      "Random Pruning Iteration: 18\n",
      "Number of Zero Weights: 494104.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9819861358432969\n",
      "Test Accuracy: 0.6195\n",
      "Random Pruning Iteration: 19\n",
      "Number of Zero Weights: 495917.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9855893061561943\n",
      "Test Accuracy: 0.5957\n",
      "Random Pruning Iteration: 20\n",
      "Number of Zero Weights: 497367.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9884710474433986\n",
      "Test Accuracy: 0.5452\n",
      "Random Pruning Iteration: 21\n",
      "Number of Zero Weights: 498527.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.990776440473162\n",
      "Test Accuracy: 0.5109\n",
      "Random Pruning Iteration: 22\n",
      "Number of Zero Weights: 499455.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9926207548969728\n",
      "Test Accuracy: 0.4642\n",
      "Random Pruning Iteration: 23\n",
      "Number of Zero Weights: 500198.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9940973988806919\n",
      "Test Accuracy: 0.4061\n",
      "Random Pruning Iteration: 24\n",
      "Number of Zero Weights: 500792.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9952779191045535\n",
      "Test Accuracy: 0.3375\n",
      "Random Pruning Iteration: 25\n",
      "Number of Zero Weights: 501267.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.996221937802086\n",
      "Test Accuracy: 0.3026\n",
      "Random Pruning Iteration: 26\n",
      "Number of Zero Weights: 501647.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9969771527601119\n",
      "Test Accuracy: 0.2516\n",
      "Random Pruning Iteration: 27\n",
      "Number of Zero Weights: 501951.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9975813247265327\n",
      "Test Accuracy: 0.2023\n",
      "Random Pruning Iteration: 28\n",
      "Number of Zero Weights: 502194.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9980642648181124\n",
      "Test Accuracy: 0.1711\n",
      "Random Pruning Iteration: 29\n",
      "Number of Zero Weights: 502389.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9984518093360468\n",
      "Test Accuracy: 0.1426\n",
      "Random Pruning Iteration: 30\n",
      "Number of Zero Weights: 502545.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9987618449503943\n",
      "Test Accuracy: 0.1498\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    torch.manual_seed(i)\n",
    "    model = get_network('ConvNetW128', 3,100)\n",
    "    RandomPruning(model, 'random_c10_seed' + str(i), path, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 60, amount = .2, save_model = False, seed = i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
