{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51ecf34-d1ab-4285-beb2-0aaf3e5bdb60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T18:20:00.691279Z",
     "iopub.status.busy": "2023-05-31T18:20:00.690678Z",
     "iopub.status.idle": "2023-05-31T18:20:11.792732Z",
     "shell.execute_reply": "2023-05-31T18:20:11.791912Z",
     "shell.execute_reply.started": "2023-05-31T18:20:00.691257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.13.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (66.1.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: kornia in /usr/local/lib/python3.9/dist-packages (0.6.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from kornia) (23.0)\n",
      "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from kornia) (1.12.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: optuna in /usr/local/lib/python3.9/dist-packages (3.2.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.41)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.11.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.23.4)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/dist-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.4.0)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.models import resnet50, resnet34, resnet18, wide_resnet50_2, ResNet50_Weights, alexnet\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from flax.training import checkpoints\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "!pip install wandb\n",
    "!pip install kornia\n",
    "!pip install optuna\n",
    "import optuna\n",
    "import kornia\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131a0bf1-a86b-4af0-9767-54de55893237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T18:20:11.796077Z",
     "iopub.status.busy": "2023-05-31T18:20:11.795927Z",
     "iopub.status.idle": "2023-05-31T18:20:11.871066Z",
     "shell.execute_reply": "2023-05-31T18:20:11.870340Z",
     "shell.execute_reply.started": "2023-05-31T18:20:11.796059Z"
    }
   },
   "outputs": [],
   "source": [
    "from networks import ConvNet, AlexNet\n",
    "from distill import ParamDiffAug\n",
    "from utils import evaluate_synset, get_network\n",
    "import argparse\n",
    "#labels_train = torch.load('/datasets/mtt-cifar10-50-ipc/cifar10_50ipc_labels.pt')\n",
    "#images_train = torch.load('/datasets/mtt-cifar10-50-ipc/cifar10_50ipc_images.pt')\n",
    "labels_train = torch.load('./data/cifar100_10ipc_labels.pt')\n",
    "images_train = torch.load('./data/cifar100_10ipc_images.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7dd09d-22f0-43c7-8a0d-7afddd0ab18e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T18:20:11.872662Z",
     "iopub.status.busy": "2023-05-31T18:20:11.872466Z",
     "iopub.status.idle": "2023-05-31T18:20:15.857947Z",
     "shell.execute_reply": "2023-05-31T18:20:15.857380Z",
     "shell.execute_reply.started": "2023-05-31T18:20:11.872646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_dataset = torchvision.datasets.CIFAR100(root = './data',\n",
    "                                                    train = True,\n",
    "                                                    transform = transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616]),]),\n",
    "                                                    download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR100(root = './data',\n",
    "                                                    train = False,\n",
    "                                                    transform = transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616]),]),\n",
    "                                                    download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.Resize((32,32)),  #resises the image so it can be perfect for our model.\n",
    "                                      transforms.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n",
    "                                      transforms.RandomRotation(10),     #Rotates the image to a specified angel\n",
    "                                      transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
    "                                      transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n",
    "                                      transforms.ToTensor(), # comvert the image to tensor so that it can work with torch\n",
    "                                      transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616]), #Normalize all the images\n",
    "                               ])\n",
    "\n",
    "\n",
    "augmented_train_dataset = torchvision.datasets.CIFAR100(root = './data',\n",
    "                                                    train = True,\n",
    "                                                    transform = transform_train,\n",
    "                                                    download=True)\n",
    "\n",
    "augmented_train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0cd085f-5189-4ed5-9074-9ab264e0fe92",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-23T19:36:01.112947Z",
     "iopub.status.busy": "2023-05-23T19:36:01.112160Z",
     "iopub.status.idle": "2023-05-23T19:36:01.173626Z",
     "shell.execute_reply": "2023-05-23T19:36:01.172543Z",
     "shell.execute_reply.started": "2023-05-23T19:36:01.112912Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#Get pretrained model to determine what is easy/hard\u001b[39;00m\n\u001b[1;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m AlexNet(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m args \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mNamespace(lr_net\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.01\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_eval_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;124m'\u001b[39m,batch_train\u001b[38;5;241m=\u001b[39m\u001b[43mbatch_size\u001b[49m,dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar10\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,dsa_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_crop_cutout_flip_scale_rotate\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa_param \u001b[38;5;241m=\u001b[39m ParamDiffAug(), dc_aug_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zca_trans\u001b[38;5;241m=\u001b[39mkornia\u001b[38;5;241m.\u001b[39menhance\u001b[38;5;241m.\u001b[39mZCAWhitening(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, compute_inv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;66;03m#, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m pretrained_model, acc_train_list, acc_test \u001b[38;5;241m=\u001b[39m evaluate_synset(\u001b[38;5;241m7\u001b[39m, model,images_train,labels_train,test_loader,args)\n\u001b[1;32m     54\u001b[0m easy_train_dataset \u001b[38;5;241m=\u001b[39m EasyHardCIFAR10Dataset(root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained_model \u001b[38;5;241m=\u001b[39m pretrained_model, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124measy\u001b[39m\u001b[38;5;124m'\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "class RandomCIFAR10Dataset(Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None, num_samples=1000):\n",
    "        self.cifar = torchvision.datasets.CIFAR10(root, train=True, download=True, transform=transform, target_transform=target_transform)\n",
    "        self.num_samples = num_samples\n",
    "        self.indices = torch.randperm(len(self.cifar))[:self.num_samples]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.cifar[self.indices[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "class EasyHardCIFAR10Dataset(Dataset):\n",
    "    def __init__(self, root, pretrained_model, transform=None, target_transform=None, mode='easy', num_samples=1000):\n",
    "        assert mode in ['easy', 'hard'], \"Mode should be 'easy' or 'hard'\"\n",
    "        self.cifar = CIFAR10(root, train=True, download=True, transform=transform, target_transform=target_transform)\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.mode = mode\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        self.pretrained_model.eval()\n",
    "        with torch.no_grad():\n",
    "            data, targets = zip(*[(data, target) for data, target in self.cifar])\n",
    "            data = torch.stack(data)\n",
    "            targets = torch.tensor(targets)\n",
    "            outputs = self.pretrained_model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "            # Get confidence scores and sort them\n",
    "            confidence_scores, indices = torch.sort(probs.max(dim=1).values, descending=True)\n",
    "            sorted_preds = preds[indices]\n",
    "            sorted_targets = targets[indices]\n",
    "\n",
    "            if mode == 'easy':\n",
    "                mask = sorted_preds == sorted_targets\n",
    "            else:  # mode == 'hard'\n",
    "                mask = sorted_preds != sorted_targets\n",
    "\n",
    "            # Select num_samples many samples\n",
    "            self.indices = indices[mask][:self.num_samples].tolist()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.cifar[self.indices[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "#Get pretrained model to determine what is easy/hard\n",
    "model = AlexNet(3,10).to('cuda')\n",
    "args = argparse.Namespace(lr_net='.01', device='cuda', epoch_eval_train='1000',batch_train=batch_size,dataset='cifar10',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)) #, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "pretrained_model, acc_train_list, acc_test = evaluate_synset(7, model,images_train,labels_train,test_loader,args)\n",
    "\n",
    "easy_train_dataset = EasyHardCIFAR10Dataset(root = './data', pretrained_model = pretrained_model, transform=None, target_transform=None, mode='easy', num_samples=1000)\n",
    "\n",
    "easy_train_loader = torch.utils.data.DataLoader(dataset = easy_train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "hard_train_dataset = EasyHardCIFAR10Dataset(root = './data', pretrained_model = pretrained_model, transform=None, target_transform=None, mode='hard', num_samples=1000)\n",
    "\n",
    "hard_train_loader = torch.utils.data.DataLoader(dataset = hard_train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "random_train_dataset = RandomCIFAR10Dataset(root = './data', transform=None, target_transform=None, num_samples=1000)\n",
    "\n",
    "random_train_loader = torch.utils.data.DataLoader(dataset = random_train_dataset,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893abb26-d2bb-406a-ab58-9d68cf9c6438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T18:20:15.859459Z",
     "iopub.status.busy": "2023-05-31T18:20:15.859097Z",
     "iopub.status.idle": "2023-05-31T18:20:15.884642Z",
     "shell.execute_reply": "2023-05-31T18:20:15.884226Z",
     "shell.execute_reply.started": "2023-05-31T18:20:15.859437Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model,train_loader, num_epochs, lr = .0008, weight_decay = .0008, gamma = .15, milestones = [50,65,80]):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    cost = nn.CrossEntropyLoss()\n",
    "    scheduler = MultiStepLR(optimizer, milestones=milestones, gamma= gamma)\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = cost(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "            \n",
    "def test(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(test_loader): \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            test_output = model(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            correct += (pred_y == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        accuracy = correct / total\n",
    "\n",
    "    print('Test Accuracy:', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def get_parameters_to_prune(model):\n",
    "    parameters_to_prune = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "    return tuple(parameters_to_prune)\n",
    "\n",
    "def sparsity_print(model):\n",
    "    prune.global_unstructured(get_parameters_to_prune(model),pruning_method=prune.L1Unstructured,amount=0)\n",
    "    zero = total = 0\n",
    "    for module, _ in get_parameters_to_prune(model):\n",
    "        zero += float(torch.sum(module.weight == 0))\n",
    "        total += float(module.weight.nelement())\n",
    "    print('Number of Zero Weights:', zero)\n",
    "    print('Total Number of Weights:', total)\n",
    "    print('Sparsity', zero/total)\n",
    "    #TODO: Implement Node Sparsity\n",
    "    return zero, total\n",
    "\n",
    "#Standard IMP with Weight Rewinding, name is a string that allows us to save models/logs appropriately, path is the location of folder we save to, start_iter should be 0 but if a experiment stops halfway through it allows us to begin there,\n",
    "#amount = % params pruned each pruning iteration, save_model downloads each model at every iter, reinit is boolean value if we want to test results on reinitialized weights\n",
    "#reinit_model is the specific model that holds the reinitialized weights\n",
    "def LotteryTicketRewinding(model, name, path, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 60, k = 1, amount = .2, save_model = True, seed = 0, reinit = False, reinit_model = None):\n",
    "    torch.manual_seed(seed)\n",
    "    zeros = []\n",
    "    totals = []\n",
    "    acc = []\n",
    "    reinit_acc = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    \n",
    "    #Create Rewind Weights after training K epochs\n",
    "    train(model, train_loader,num_epochs = k)\n",
    "    torch.save(model.state_dict(), path + name + '_RewindWeights' + '_' + str(k))\n",
    "    model_rewind = copy.deepcopy(model).to(device)\n",
    "    \n",
    "    #Finish off the pretraining\n",
    "    train(model, train_loader,num_epochs = num_epochs - k)\n",
    "\n",
    "    #Lottery Ticket Rewinding: Prune, Rewind, Train\n",
    "    for i in range(start_iter,end_iter):\n",
    "        print('LTR Iteration:', i+1)\n",
    "        #Prune\n",
    "        prune.global_unstructured(get_parameters_to_prune(model),pruning_method=prune.L1Unstructured,amount=amount)\n",
    "        #Rewind Weights\n",
    "        for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "            with torch.no_grad():\n",
    "                module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                module.weight_orig.copy_(module_rewind.weight)\n",
    "        #Train Weights\n",
    "        train(model, train_loader,num_epochs = num_epochs)\n",
    "        \n",
    "        #Log Results\n",
    "        zero, total = sparsity_print(model)\n",
    "        zeros.append(zero)\n",
    "        totals.append(total)\n",
    "        acc.append(test(model, test_loader))\n",
    "        if save_model:\n",
    "            torch.save(model.state_dict(), path + name + '_iter' + str(i+1))\n",
    "            \n",
    "        if reinit:\n",
    "            #Rewind Weights\n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_reinit = get_parameters_to_prune(reinit_model)[idx][0]\n",
    "                    module.weight_orig.copy_(module_reinit.weight)\n",
    "                    \n",
    "            train(model, train_loader,num_epochs = num_epochs)\n",
    "            reinit_acc.append(test(model, test_loader))\n",
    "            \n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                    module.weight_orig.copy_(module_rewind.weight)\n",
    "        else:\n",
    "            reinit_acc.append(0)\n",
    "            \n",
    "        np.save(path + name + '_log', np.array([acc,zeros,totals,reinit_acc]))\n",
    "    \n",
    "    pass\n",
    "  \n",
    "#Generate full sparsity curve with retraining for random pruning, this is not a method to compute a single, high-sparisty model with random pruning. This generates and trains models at all sparsities for comparison\n",
    "def RandomPruning(model, name, path, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 60, amount = .2, save_model = True, seed = 0):\n",
    "    torch.manual_seed(seed)\n",
    "    zeros = []\n",
    "    totals = []\n",
    "    acc = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    \n",
    "    model_rewind = copy.deepcopy(model).to(device)\n",
    "    \n",
    "    for i in range(start_iter,end_iter):\n",
    "        print('Random Pruning Iteration:', i+1)\n",
    "        #Prune\n",
    "        prune.global_unstructured(get_parameters_to_prune(model),pruning_method=prune.RandomUnstructured,amount=amount)\n",
    "        #Train Weights\n",
    "        train(model, train_loader,num_epochs = num_epochs)\n",
    "        \n",
    "        #Log Results\n",
    "        zero, total = sparsity_print(model)\n",
    "        zeros.append(zero)\n",
    "        totals.append(total)\n",
    "        acc.append(test(model, test_loader))\n",
    "\n",
    "            \n",
    "        #Rewind Weights to save them\n",
    "        for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "            with torch.no_grad():\n",
    "                module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                module.weight_orig.copy_(module_rewind.weight)\n",
    "                \n",
    "        if save_model:\n",
    "            torch.save(model.state_dict(), path + name + '_iter' + str(i+1))\n",
    "            \n",
    "        np.save(path + name + '_log', np.array([acc,zeros,totals]))\n",
    "    \n",
    "#Generate full sparsity curve to compare with LTR\n",
    "def DistilledPruning(model, name, path, images_train, labels_train, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs_distilled = 1000, num_epochs_real = 60, k = 0, amount = .2, save_model = True, validate = False, seed = 0, reinit = False, reinit_model = None, distilled_lr = .01):\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    accs = []\n",
    "    zeros = []\n",
    "    totals = []\n",
    "    reinit_acc = []\n",
    "    \n",
    "    model_rewind = copy.deepcopy(model).to(device)\n",
    "    torch.save(model.state_dict(), path + name + '_RewindWeights' + '_' + str(k))\n",
    "    \n",
    "    if k != 0:\n",
    "        args = argparse.Namespace(lr_net=str(distilled_lr), device='cuda', epoch_eval_train=str(k),batch_train=512,dataset='cifar10',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)) #, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "        model_rewind, acc_train_list, acc_test = evaluate_synset(0, model_rewind,images_train,labels_train,test_loader,args)\n",
    "        \n",
    "    \n",
    "    for i in range(start_iter,end_iter):\n",
    "        print('Distilled Pruning Iteration ', i)\n",
    "        args = argparse.Namespace(lr_net='.01', device='cuda', epoch_eval_train=str(num_epochs_distilled),batch_train=512,dataset='cifar10',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)) #, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "        #MTT Training on Distilled Data\n",
    "        model, acc_train_list, acc_test = evaluate_synset(i+1, model,images_train,labels_train,test_loader,args)\n",
    "        prune.global_unstructured(get_parameters_to_prune(model),pruning_method=prune.L1Unstructured,amount=amount)\n",
    "        #Rewind Weights\n",
    "        for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "            with torch.no_grad():\n",
    "                module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                module.weight_orig.copy_(module_rewind.weight)\n",
    "    \n",
    "        if save_model:\n",
    "            torch.save(model.state_dict(), path + name + '_iter' + str(i+1))\n",
    "            \n",
    "        if validate:\n",
    "            train(model, train_loader,num_epochs = num_epochs_real)\n",
    "            accs.append(test(model, test_loader))\n",
    "            zero, total = sparsity_print(model)\n",
    "            zeros.append(zero)\n",
    "            totals.append(total)\n",
    "            #Rewind Weights\n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                    module.weight_orig.copy_(module_rewind.weight)\n",
    "                    \n",
    "            np.save(path + name + '_log', np.array([accs, zeros, totals, reinit_acc]))\n",
    "        \n",
    "        if reinit:\n",
    "            #Rewind Weights to Reinit Model\n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_reinit = get_parameters_to_prune(reinit_model)[idx][0]\n",
    "                    module.weight_orig.copy_(module_reinit.weight)\n",
    "                    \n",
    "            train(model, train_loader,num_epochs = num_epochs_real)\n",
    "            reinit_acc.append(test(model, test_loader))\n",
    "            \n",
    "            for idx, (module, _) in enumerate(get_parameters_to_prune(model)):\n",
    "                with torch.no_grad():\n",
    "                    module_rewind = get_parameters_to_prune(model_rewind)[idx][0]\n",
    "                    module.weight_orig.copy_(module_rewind.weight)\n",
    "            np.save(path + name + '_log', np.array([accs, zeros, totals, reinit_acc]))\n",
    "        else:\n",
    "            reinit_acc.append(0)\n",
    "            \n",
    "    if not validate:\n",
    "        train(model, train_loader,num_epochs = num_epochs_real)\n",
    "        acc = (test(model, test_loader))\n",
    "        zero, total = sparsity_print(model)\n",
    "        np.save(path + name + '_log', np.array([acc, zero, total, reinit]))\n",
    "    \n",
    "path = './model_results_cifar100/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f51b0f-23af-4196-a0e7-61cf69325e3b",
   "metadata": {},
   "source": [
    "Distilled Training Params: .085 lr and 1300 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7620b4b2-a6b9-4e28-88e9-e4065487720b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T16:22:50.356044Z",
     "iopub.status.busy": "2023-05-30T16:22:50.355507Z",
     "iopub.status.idle": "2023-05-30T16:26:49.767398Z",
     "shell.execute_reply": "2023-05-30T16:26:49.766487Z",
     "shell.execute_reply.started": "2023-05-30T16:22:50.356021Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:55<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:23:45] Evaluate_01: epoch = 0500 train time = 55 s train loss = 0.007421 train acc = 1.0000, test acc = 0.3796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:53<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:24:39] Evaluate_01: epoch = 0500 train time = 53 s train loss = 0.003408 train acc = 1.0000, test acc = 0.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:52<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:25:32] Evaluate_01: epoch = 0500 train time = 52 s train loss = 0.004517 train acc = 1.0000, test acc = 0.3931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:54<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:26:27] Evaluate_01: epoch = 0500 train time = 54 s train loss = 0.002383 train acc = 1.0000, test acc = 0.3780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 217/501 [00:22<00:29,  9.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m args \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mNamespace(lr_net\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m.09\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_eval_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m500\u001b[39m),batch_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar100\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,dsa_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_crop_cutout_flip_scale_rotate\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa_param \u001b[38;5;241m=\u001b[39m ParamDiffAug(), dc_aug_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zca_trans\u001b[38;5;241m=\u001b[39mkornia\u001b[38;5;241m.\u001b[39menhance\u001b[38;5;241m.\u001b[39mZCAWhitening(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, compute_inv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))                        \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     model, acc_train_list, acc_test \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_synset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimages_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/mtt_distillation/utils.py:371\u001b[0m, in \u001b[0;36mevaluate_synset\u001b[0;34m(it_eval, net, images_train, labels_train, testloader, args, return_loss, texture)\u001b[0m\n\u001b[1;32m    368\u001b[0m loss_train_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(Epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 371\u001b[0m     loss_train, acc_train \u001b[38;5;241m=\u001b[39m \u001b[43mepoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     acc_train_list\u001b[38;5;241m.\u001b[39mappend(acc_train)\n\u001b[1;32m    373\u001b[0m     loss_train_list\u001b[38;5;241m.\u001b[39mappend(loss_train)\n",
      "File \u001b[0;32m/notebooks/mtt_distillation/utils.py:343\u001b[0m, in \u001b[0;36mepoch\u001b[0;34m(mode, dataloader, net, optimizer, criterion, args, aug, texture)\u001b[0m\n\u001b[1;32m    341\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    342\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 343\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m loss_avg \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_exp\n\u001b[1;32m    346\u001b[0m acc_avg \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_exp\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/sgd.py:146\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m             momentum_buffer_list\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_buffer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 146\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/sgd.py:197\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 197\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m     \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m     \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/sgd.py:241\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    238\u001b[0m         d_p \u001b[38;5;241m=\u001b[39m buf\n\u001b[1;32m    240\u001b[0m alpha \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;28;01mif\u001b[39;00m maximize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39mlr\n\u001b[0;32m--> 241\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_network('ConvNetW128', 3, 100)\n",
    "args = argparse.Namespace(lr_net=str(.09), device='cuda', epoch_eval_train=str(500),batch_train=100,dataset='cifar100',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True))                        \n",
    "for i in range(20):\n",
    "    model, acc_train_list, acc_test = evaluate_synset(1, model,images_train,labels_train,test_loader,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b423c72d-ea92-4904-a534-ecc4777513ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T16:16:20.736463Z",
     "iopub.status.busy": "2023-05-30T16:16:20.736180Z",
     "iopub.status.idle": "2023-05-30T16:22:28.527055Z",
     "shell.execute_reply": "2023-05-30T16:22:28.525973Z",
     "shell.execute_reply.started": "2023-05-30T16:16:20.736444Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-05-30 16:16:20,740] A new study created in memory with name: no-name-c41bfd89-1a61-49e3-b654-addf8e24482e\n",
      "100%|██████████| 1001/1001 [01:12<00:00, 13.87it/s]\n",
      "[I 2023-05-30 16:17:32,905] Trial 0 finished with value: 0.3678 and parameters: {'learning_rate': 0.026211558904925995}. Best is trial 0 with value: 0.3678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:17:32] Evaluate_01: epoch = 1000 train time = 72 s train loss = 0.012755 train acc = 1.0000, test acc = 0.3678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [01:12<00:00, 13.76it/s]\n",
      "[I 2023-05-30 16:18:45,667] Trial 1 finished with value: 0.3886 and parameters: {'learning_rate': 0.08994542835725695}. Best is trial 1 with value: 0.3886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:18:45] Evaluate_01: epoch = 1000 train time = 72 s train loss = 0.001732 train acc = 1.0000, test acc = 0.3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [01:12<00:00, 13.87it/s]\n",
      "[I 2023-05-30 16:19:57,853] Trial 2 finished with value: 0.3878 and parameters: {'learning_rate': 0.06305983425758348}. Best is trial 1 with value: 0.3886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:19:57] Evaluate_01: epoch = 1000 train time = 72 s train loss = 0.002157 train acc = 1.0000, test acc = 0.3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [01:12<00:00, 13.88it/s]\n",
      "[I 2023-05-30 16:21:09,998] Trial 3 finished with value: 0.3763 and parameters: {'learning_rate': 0.02628938966555709}. Best is trial 1 with value: 0.3886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:21:09] Evaluate_01: epoch = 1000 train time = 72 s train loss = 0.002632 train acc = 1.0000, test acc = 0.3763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [01:12<00:00, 13.82it/s]\n",
      "[I 2023-05-30 16:22:22,448] Trial 4 finished with value: 0.3874 and parameters: {'learning_rate': 0.09087063014134104}. Best is trial 1 with value: 0.3886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:22:22] Evaluate_01: epoch = 1000 train time = 72 s train loss = 0.003265 train acc = 1.0000, test acc = 0.3874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 82/1001 [00:05<01:06, 13.73it/s]\n",
      "[W 2023-05-30 16:22:28,431] Trial 5 failed with parameters: {'learning_rate': 0.016780346092693223} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_32/3820575577.py\", line 9, in objective\n",
      "    model, acc_train_list, acc_test = evaluate_synset(1, model,images_train,labels_train,test_loader,args)\n",
      "  File \"/notebooks/mtt_distillation/utils.py\", line 371, in evaluate_synset\n",
      "    loss_train, acc_train = epoch('train', trainloader, net, optimizer, criterion, args, aug=True, texture=texture)\n",
      "  File \"/notebooks/mtt_distillation/utils.py\", line 322, in epoch\n",
      "    img = DiffAugment(img, args.dsa_strategy, param=args.dsa_param)\n",
      "  File \"/notebooks/mtt_distillation/utils.py\", line 542, in DiffAugment\n",
      "    x = f(x, param)\n",
      "  File \"/notebooks/mtt_distillation/utils.py\", line 558, in rand_scale\n",
      "    theta = [[[sx[i], 0,  0],\n",
      "  File \"/notebooks/mtt_distillation/utils.py\", line 559, in <listcomp>\n",
      "    [0,  sy[i], 0],] for i in range(x.shape[0])]\n",
      "KeyboardInterrupt\n",
      "[W 2023-05-30 16:22:28,433] Trial 5 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acc_test\n\u001b[1;32m     13\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler())\n\u001b[0;32m---> 14\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [8], line 9\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m get_network(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConvNetW128\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      8\u001b[0m args \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mNamespace(lr_net\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_eval_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m1000\u001b[39m),batch_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar100\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,dsa_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_crop_cutout_flip_scale_rotate\u001b[39m\u001b[38;5;124m'\u001b[39m,dsa_param \u001b[38;5;241m=\u001b[39m ParamDiffAug(), dc_aug_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zca_trans\u001b[38;5;241m=\u001b[39mkornia\u001b[38;5;241m.\u001b[39menhance\u001b[38;5;241m.\u001b[39mZCAWhitening(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, compute_inv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))                        \n\u001b[0;32m----> 9\u001b[0m model, acc_train_list, acc_test \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_synset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimages_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc_test\n",
      "File \u001b[0;32m/notebooks/mtt_distillation/utils.py:371\u001b[0m, in \u001b[0;36mevaluate_synset\u001b[0;34m(it_eval, net, images_train, labels_train, testloader, args, return_loss, texture)\u001b[0m\n\u001b[1;32m    368\u001b[0m loss_train_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(Epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 371\u001b[0m     loss_train, acc_train \u001b[38;5;241m=\u001b[39m \u001b[43mepoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     acc_train_list\u001b[38;5;241m.\u001b[39mappend(acc_train)\n\u001b[1;32m    373\u001b[0m     loss_train_list\u001b[38;5;241m.\u001b[39mappend(loss_train)\n",
      "File \u001b[0;32m/notebooks/mtt_distillation/utils.py:322\u001b[0m, in \u001b[0;36mepoch\u001b[0;34m(mode, dataloader, net, optimizer, criterion, args, aug, texture)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aug:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdsa:\n\u001b[0;32m--> 322\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mDiffAugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsa_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsa_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m         img \u001b[38;5;241m=\u001b[39m augment(img, args\u001b[38;5;241m.\u001b[39mdc_aug_param, device\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/notebooks/mtt_distillation/utils.py:542\u001b[0m, in \u001b[0;36mDiffAugment\u001b[0;34m(x, strategy, seed, param)\u001b[0m\n\u001b[1;32m    540\u001b[0m     p \u001b[38;5;241m=\u001b[39m pbties[torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(pbties), size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m AUGMENT_FNS[p]:\n\u001b[0;32m--> 542\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    544\u001b[0m     exit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError ZH: unknown augmentation mode.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/mtt_distillation/utils.py:558\u001b[0m, in \u001b[0;36mrand_scale\u001b[0;34m(x, param)\u001b[0m\n\u001b[1;32m    556\u001b[0m set_seed_DiffAug(param)\n\u001b[1;32m    557\u001b[0m sy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m (ratio \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mratio) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mratio\n\u001b[0;32m--> 558\u001b[0m theta \u001b[38;5;241m=\u001b[39m [[[sx[i], \u001b[38;5;241m0\u001b[39m,  \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    559\u001b[0m         [\u001b[38;5;241m0\u001b[39m,  sy[i], \u001b[38;5;241m0\u001b[39m],] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m    560\u001b[0m theta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(theta, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mbatchmode: \u001b[38;5;66;03m# batch-wise:\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/mtt_distillation/utils.py:559\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    556\u001b[0m set_seed_DiffAug(param)\n\u001b[1;32m    557\u001b[0m sy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m (ratio \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mratio) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mratio\n\u001b[1;32m    558\u001b[0m theta \u001b[38;5;241m=\u001b[39m [[[sx[i], \u001b[38;5;241m0\u001b[39m,  \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 559\u001b[0m         [\u001b[38;5;241m0\u001b[39m,  sy[i], \u001b[38;5;241m0\u001b[39m],] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m    560\u001b[0m theta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(theta, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mbatchmode: \u001b[38;5;66;03m# batch-wise:\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n",
    "              }\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    model = get_network('ConvNetW128', 3, 100)\n",
    "    args = argparse.Namespace(lr_net=str(params['learning_rate']), device='cuda', epoch_eval_train=str(1000),batch_train=512,dataset='cifar100',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True))                        \n",
    "    model, acc_train_list, acc_test = evaluate_synset(1, model,images_train,labels_train,test_loader,args)\n",
    "\n",
    "    return acc_test\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e7c885a-47f1-49b3-8cff-97b6a057898e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T16:29:40.688940Z",
     "iopub.status.busy": "2023-05-30T16:29:40.688301Z",
     "iopub.status.idle": "2023-05-30T16:31:14.136578Z",
     "shell.execute_reply": "2023-05-30T16:31:14.135932Z",
     "shell.execute_reply.started": "2023-05-30T16:29:40.688914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1301/1301 [01:33<00:00, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-30 16:31:14] Evaluate_01: epoch = 1300 train time = 93 s train loss = 0.005592 train acc = 1.0000, test acc = 0.3993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = get_network('ConvNetW128', 3, 100)\n",
    "args = argparse.Namespace(lr_net='.09', device='cuda', epoch_eval_train=str(1300),batch_train=512,dataset='cifar100',dsa=True,dsa_strategy='color_crop_cutout_flip_scale_rotate',dsa_param = ParamDiffAug(), dc_aug_param=None, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)) #, zca_trans=kornia.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "model, acc_train_list, acc_test = evaluate_synset(1, model,images_train,labels_train,test_loader,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9478a-58a5-4e26-9289-90a36529db4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T18:20:33.240209Z",
     "iopub.status.busy": "2023-05-31T18:20:33.239478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled Pruning Iteration  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1251 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 1251/1251 [00:55<00:00, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-31 18:21:30] Evaluate_01: epoch = 1250 train time = 55 s train loss = 0.029523 train acc = 1.0000, test acc = 0.3745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/2071708352.py:197: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.save(path + name + '_log', np.array([accs, zeros, totals, reinit_acc]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5176\n",
      "Number of Zero Weights: 100634.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.2000007949631137\n",
      "Distilled Pruning Iteration  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:54<00:00, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-31 18:36:19] Evaluate_02: epoch = 1250 train time = 54 s train loss = 0.017830 train acc = 1.0000, test acc = 0.3730\n",
      "Test Accuracy: 0.5025\n",
      "Number of Zero Weights: 181141.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.3600010334520478\n",
      "Distilled Pruning Iteration  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:54<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-31 18:51:10] Evaluate_03: epoch = 1250 train time = 54 s train loss = 0.004405 train acc = 1.0000, test acc = 0.3734\n",
      "Test Accuracy: 0.495\n",
      "Number of Zero Weights: 245546.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.4880000317985245\n",
      "Distilled Pruning Iteration  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:53<00:00, 23.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-31 19:06:01] Evaluate_04: epoch = 1250 train time = 53 s train loss = 0.003360 train acc = 1.0000, test acc = 0.3712\n",
      "Test Accuracy: 0.4791\n",
      "Number of Zero Weights: 297070.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.590399230475706\n",
      "Distilled Pruning Iteration  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:54<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-31 19:20:54] Evaluate_05: epoch = 1250 train time = 54 s train loss = 0.003594 train acc = 1.0000, test acc = 0.3687\n",
      "Test Accuracy: 0.4738\n",
      "Number of Zero Weights: 338290.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.6723201793436785\n",
      "Distilled Pruning Iteration  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:54<00:00, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-31 19:35:49] Evaluate_06: epoch = 1250 train time = 54 s train loss = 0.014486 train acc = 1.0000, test acc = 0.3672\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    torch.manual_seed(i)\n",
    "    model = get_network('ConvNetW128', 3, 100)\n",
    "    DistilledPruning(model, 'dist_c100_ipc10_seed' + str(i), path, images_train, labels_train, train_loader, test_loader, start_iter = 0, end_iter = 20, num_epochs_distilled = 1250, num_epochs_real = 120, k = 0, amount = .2, save_model = False, validate = True, seed = 0, reinit = False, reinit_model = None, distilled_lr = .09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1763be-3343-44f1-b2ad-3897c4c1adfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T02:40:42.664587Z",
     "iopub.status.busy": "2023-05-26T02:40:42.664303Z",
     "iopub.status.idle": "2023-05-26T06:26:45.241275Z",
     "shell.execute_reply": "2023-05-26T06:26:45.240325Z",
     "shell.execute_reply.started": "2023-05-26T02:40:42.664566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTR Iteration: 1\n",
      "Number of Zero Weights: 63770.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.20000125451625853\n",
      "Test Accuracy: 0.8143\n",
      "LTR Iteration: 2\n",
      "Number of Zero Weights: 114786.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.36000225812926534\n",
      "Test Accuracy: 0.8132\n",
      "LTR Iteration: 3\n",
      "Number of Zero Weights: 155598.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.48800055198715375\n",
      "Test Accuracy: 0.8118\n",
      "LTR Iteration: 4\n",
      "Number of Zero Weights: 188248.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.590400441589723\n",
      "Test Accuracy: 0.8094\n",
      "LTR Iteration: 5\n",
      "Number of Zero Weights: 214368.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.6723203532717784\n",
      "Test Accuracy: 0.8101\n",
      "LTR Iteration: 6\n",
      "Number of Zero Weights: 235264.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.7378562826174228\n",
      "Test Accuracy: 0.806\n",
      "LTR Iteration: 7\n",
      "Number of Zero Weights: 251981.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.7902856533520675\n",
      "Test Accuracy: 0.8042\n",
      "LTR Iteration: 8\n",
      "Number of Zero Weights: 265354.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.8322272681653954\n",
      "Test Accuracy: 0.8029\n",
      "LTR Iteration: 9\n",
      "Number of Zero Weights: 276053.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.8657824417904456\n",
      "Test Accuracy: 0.7962\n",
      "LTR Iteration: 10\n",
      "Number of Zero Weights: 284612.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.8926259534323565\n",
      "Test Accuracy: 0.7945\n",
      "LTR Iteration: 11\n",
      "Number of Zero Weights: 291459.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9141001354877559\n",
      "Test Accuracy: 0.7851\n",
      "LTR Iteration: 12\n",
      "Number of Zero Weights: 296937.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.931280735648334\n",
      "Test Accuracy: 0.7749\n",
      "LTR Iteration: 13\n",
      "Number of Zero Weights: 301319.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9450239612605379\n",
      "Test Accuracy: 0.7725\n",
      "LTR Iteration: 14\n",
      "Number of Zero Weights: 304825.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9560197962665596\n",
      "Test Accuracy: 0.7663\n",
      "LTR Iteration: 15\n",
      "Number of Zero Weights: 307630.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9648170915295062\n",
      "Test Accuracy: 0.7679\n",
      "LTR Iteration: 16\n",
      "Number of Zero Weights: 309874.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9718549277398635\n",
      "Test Accuracy: 0.757\n",
      "LTR Iteration: 17\n",
      "Number of Zero Weights: 311669.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.97748456945002\n",
      "Test Accuracy: 0.751\n",
      "LTR Iteration: 18\n",
      "Number of Zero Weights: 313105.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9819882828181453\n",
      "Test Accuracy: 0.7341\n",
      "LTR Iteration: 19\n",
      "Number of Zero Weights: 314254.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9855918807707748\n",
      "Test Accuracy: 0.7274\n",
      "LTR Iteration: 20\n",
      "Number of Zero Weights: 315173.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9884741318747491\n",
      "Test Accuracy: 0.7071\n",
      "LTR Iteration: 21\n",
      "Number of Zero Weights: 315908.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9907793054997993\n",
      "Test Accuracy: 0.6792\n",
      "LTR Iteration: 22\n",
      "Number of Zero Weights: 316496.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9926234443998394\n",
      "Test Accuracy: 0.6619\n",
      "LTR Iteration: 23\n",
      "Number of Zero Weights: 316966.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.994097501003613\n",
      "Test Accuracy: 0.6368\n",
      "LTR Iteration: 24\n",
      "Number of Zero Weights: 317342.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9952767462866319\n",
      "Test Accuracy: 0.628\n",
      "LTR Iteration: 25\n",
      "Number of Zero Weights: 317643.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9962207697711762\n",
      "Test Accuracy: 0.5611\n",
      "LTR Iteration: 26\n",
      "Number of Zero Weights: 317884.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.996976615816941\n",
      "Test Accuracy: 0.5451\n",
      "LTR Iteration: 27\n",
      "Number of Zero Weights: 318077.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9975819199116821\n",
      "Test Accuracy: 0.5434\n",
      "LTR Iteration: 28\n",
      "Number of Zero Weights: 318231.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9980649086712163\n",
      "Test Accuracy: 0.4777\n",
      "LTR Iteration: 29\n",
      "Number of Zero Weights: 318354.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9984506724207146\n",
      "Test Accuracy: 0.461\n",
      "LTR Iteration: 30\n",
      "Number of Zero Weights: 318453.0\n",
      "Total Number of Weights: 318848.0\n",
      "Sparsity 0.9987611651947009\n",
      "Test Accuracy: 0.4082\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    torch.manual_seed(i)\n",
    "    model = get_network('ConvNetW128', 3,10)\n",
    "    LotteryTicketRewinding(model, 'ltr_c10_seed' + str(i), path, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 60, k = 1, amount = .2, save_model = False, seed = i, reinit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a75ef5b-b092-4069-ad01-997f9305da6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T22:14:54.956970Z",
     "iopub.status.busy": "2023-05-25T22:14:54.956771Z",
     "iopub.status.idle": "2023-05-26T01:53:25.340736Z",
     "shell.execute_reply": "2023-05-26T01:53:25.340058Z",
     "shell.execute_reply.started": "2023-05-25T22:14:54.956949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Pruning Iteration: 1\n",
      "Number of Zero Weights: 100634.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.2000007949631137\n",
      "Test Accuracy: 0.8126\n",
      "Random Pruning Iteration: 2\n",
      "Number of Zero Weights: 181141.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.3600010334520478\n",
      "Test Accuracy: 0.7985\n",
      "Random Pruning Iteration: 3\n",
      "Number of Zero Weights: 245547.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.4880020192063088\n",
      "Test Accuracy: 0.7913\n",
      "Random Pruning Iteration: 4\n",
      "Number of Zero Weights: 297070.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.590399230475706\n",
      "Test Accuracy: 0.781\n",
      "Random Pruning Iteration: 5\n",
      "Number of Zero Weights: 338290.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.6723201793436785\n",
      "Test Accuracy: 0.7751\n",
      "Random Pruning Iteration: 6\n",
      "Number of Zero Weights: 371266.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.7378569384380564\n",
      "Test Accuracy: 0.7669\n",
      "Random Pruning Iteration: 7\n",
      "Number of Zero Weights: 397646.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.7902847557873315\n",
      "Test Accuracy: 0.7684\n",
      "Random Pruning Iteration: 8\n",
      "Number of Zero Weights: 418750.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.8322270096667514\n",
      "Test Accuracy: 0.7458\n",
      "Random Pruning Iteration: 9\n",
      "Number of Zero Weights: 435634.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.8657824026965149\n",
      "Test Accuracy: 0.7493\n",
      "Random Pruning Iteration: 10\n",
      "Number of Zero Weights: 449141.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.8926263196387687\n",
      "Test Accuracy: 0.7298\n",
      "Random Pruning Iteration: 11\n",
      "Number of Zero Weights: 459946.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9141002607479013\n",
      "Test Accuracy: 0.727\n",
      "Random Pruning Iteration: 12\n",
      "Number of Zero Weights: 468590.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9312794136352073\n",
      "Test Accuracy: 0.7261\n",
      "Random Pruning Iteration: 13\n",
      "Number of Zero Weights: 475506.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9450243258712796\n",
      "Test Accuracy: 0.7153\n",
      "Random Pruning Iteration: 14\n",
      "Number of Zero Weights: 481038.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9560186657339099\n",
      "Test Accuracy: 0.6958\n",
      "Random Pruning Iteration: 15\n",
      "Number of Zero Weights: 485464.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9648149325871279\n",
      "Test Accuracy: 0.6827\n",
      "Random Pruning Iteration: 16\n",
      "Number of Zero Weights: 489005.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9718523435512593\n",
      "Test Accuracy: 0.6704\n",
      "Random Pruning Iteration: 17\n",
      "Number of Zero Weights: 491838.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9774826698041211\n",
      "Test Accuracy: 0.6413\n",
      "Random Pruning Iteration: 18\n",
      "Number of Zero Weights: 494104.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9819861358432969\n",
      "Test Accuracy: 0.6195\n",
      "Random Pruning Iteration: 19\n",
      "Number of Zero Weights: 495917.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9855893061561943\n",
      "Test Accuracy: 0.5957\n",
      "Random Pruning Iteration: 20\n",
      "Number of Zero Weights: 497367.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9884710474433986\n",
      "Test Accuracy: 0.5452\n",
      "Random Pruning Iteration: 21\n",
      "Number of Zero Weights: 498527.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.990776440473162\n",
      "Test Accuracy: 0.5109\n",
      "Random Pruning Iteration: 22\n",
      "Number of Zero Weights: 499455.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9926207548969728\n",
      "Test Accuracy: 0.4642\n",
      "Random Pruning Iteration: 23\n",
      "Number of Zero Weights: 500198.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9940973988806919\n",
      "Test Accuracy: 0.4061\n",
      "Random Pruning Iteration: 24\n",
      "Number of Zero Weights: 500792.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9952779191045535\n",
      "Test Accuracy: 0.3375\n",
      "Random Pruning Iteration: 25\n",
      "Number of Zero Weights: 501267.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.996221937802086\n",
      "Test Accuracy: 0.3026\n",
      "Random Pruning Iteration: 26\n",
      "Number of Zero Weights: 501647.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9969771527601119\n",
      "Test Accuracy: 0.2516\n",
      "Random Pruning Iteration: 27\n",
      "Number of Zero Weights: 501951.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9975813247265327\n",
      "Test Accuracy: 0.2023\n",
      "Random Pruning Iteration: 28\n",
      "Number of Zero Weights: 502194.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9980642648181124\n",
      "Test Accuracy: 0.1711\n",
      "Random Pruning Iteration: 29\n",
      "Number of Zero Weights: 502389.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9984518093360468\n",
      "Test Accuracy: 0.1426\n",
      "Random Pruning Iteration: 30\n",
      "Number of Zero Weights: 502545.0\n",
      "Total Number of Weights: 503168.0\n",
      "Sparsity 0.9987618449503943\n",
      "Test Accuracy: 0.1498\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    torch.manual_seed(i)\n",
    "    model = get_network('ConvNetW128', 3,100)\n",
    "    RandomPruning(model, 'random_c10_seed' + str(i), path, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 60, amount = .2, save_model = False, seed = i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
